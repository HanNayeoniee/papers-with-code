{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# RNN \n",
        "\n",
        "- Data : NSMC 네이버 영화 리뷰 데이터셋\n",
        "- Model : RNN, LSTM, GRU\n",
        "- Task : 긍정/부정 분류하기 (Classification)\n",
        "- Loss : BCE loss"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hiJs6xXI2Syg"
      },
      "source": [
        "## 1. Data preprocessing functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IRKJSiSNy1Yk",
        "outputId": "f6ca8021-4e47-4f23-f8cf-48a6cd54abc4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting git+https://github.com/ssut/py-hanspell.git\n",
            "  Cloning https://github.com/ssut/py-hanspell.git to /tmp/pip-req-build-hotc78p0\n",
            "  Running command git clone -q https://github.com/ssut/py-hanspell.git /tmp/pip-req-build-hotc78p0\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from py-hanspell==1.1) (2.23.0)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2022.6.15)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->py-hanspell==1.1) (2.10)\n",
            "Building wheels for collected packages: py-hanspell\n",
            "  Building wheel for py-hanspell (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for py-hanspell: filename=py_hanspell-1.1-py3-none-any.whl size=4868 sha256=4913cdc5438dc09b57f5fc121061a75d9e1ee1d7152f81bcf11ec8af33edce83\n",
            "  Stored in directory: /tmp/pip-ephem-wheel-cache-wy8cmh5r/wheels/ab/f5/7b/d4124bb329c905301baed80e2ae45aa14e824f62ebc3ec2cc4\n",
            "Successfully built py-hanspell\n",
            "Installing collected packages: py-hanspell\n",
            "Successfully installed py-hanspell-1.1\n"
          ]
        }
      ],
      "source": [
        "!pip install git+https://github.com/ssut/py-hanspell.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "a9vFT1u6yCqu"
      },
      "outputs": [],
      "source": [
        "from hanspell import spell_checker\n",
        "#from pykospacing import Spacing\n",
        "\n",
        "# sort, unique -> 리눅스 창에서 하는 게 나음\n",
        "# 특수문자는 감정과 관련될 수 있어서 제거하지 않음\n",
        "\n",
        "# basic 전처리\n",
        "def basic_preprocess(sentence):\n",
        "    # 기호 일반화\n",
        "    punct_mapping = {\"‘\": \"'\", \"₹\": \"e\", \"´\": \"'\", \"°\": \"\", \"€\": \"e\", \"™\": \"tm\", \"√\": \" sqrt \", \"×\": \"x\", \"²\": \"2\", \"—\": \"-\", \"–\": \"-\", \"’\": \"'\", \"_\": \"-\", \"`\": \"'\", '“': '\"', '”': '\"', '“': '\"', \"£\": \"e\", '∞': 'infinity', 'θ': 'theta', '÷': '/', 'α': 'alpha', '•': '.', 'à': 'a', '−': '-', 'β': 'beta', '∅': '', '³': '3', 'π': 'pi', }\n",
        "    for p in punct_mapping:\n",
        "        sentence = sentence.replace(p, punct_mapping[p])\n",
        "    new_sentence = sentence.lower() # 대소문자 통일\n",
        "    new_sentence = new_sentence.strip() # 좌우 공백 제거\n",
        "    return new_sentence\n",
        "\n",
        "# 맞춤법 교정\n",
        "def spell_check(sentence):\n",
        "    result = spell_checker.check(sentence)\n",
        "    new_sentence = result.as_dict()['checked']\n",
        "    return new_sentence\n",
        "\n",
        "# 띄어쓰기 교정\n",
        "#def spacing_check(sentence):\n",
        "#    spacing = Spacing()\n",
        "#    new_sentence = spacing(sentence) \n",
        "#    return new_sentence\n",
        "\n",
        "# 이상한 문자 제거\n",
        "\n",
        "\n",
        "# 전체 전처리 함수\n",
        "def preprocess(sentence):\n",
        "    # 기본 전처리\n",
        "    new_sentence = basic_preprocess(sentence)\n",
        "\n",
        "    # 맞춤법\n",
        "    #new_sentence = spell_check(new_sentence)\n",
        "\n",
        "    # 띄어쓰기\n",
        "    #new_sentence = spacing_check(new_sentence)\n",
        "\n",
        "    return new_sentence"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "mwESUAw6yN63"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7h8QxVao2c9f"
      },
      "source": [
        "## 2. Prepare Dataset"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jEeUeJe82qEf"
      },
      "source": [
        "### install"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DJXH-1ZUz0-H",
        "outputId": "8b6963b2-3751-442e-e29a-9ddd73152ae5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting konlpy\n",
            "  Downloading konlpy-0.6.0-py2.py3-none-any.whl (19.4 MB)\n",
            "\u001b[K     |████████████████████████████████| 19.4 MB 1.1 MB/s \n",
            "\u001b[?25hCollecting JPype1>=0.7.0\n",
            "  Downloading JPype1-1.4.0-cp37-cp37m-manylinux_2_5_x86_64.manylinux1_x86_64.whl (453 kB)\n",
            "\u001b[K     |████████████████████████████████| 453 kB 52.0 MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy>=1.6 in /usr/local/lib/python3.7/dist-packages (from konlpy) (1.21.6)\n",
            "Requirement already satisfied: lxml>=4.1.0 in /usr/local/lib/python3.7/dist-packages (from konlpy) (4.2.6)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from JPype1>=0.7.0->konlpy) (4.1.1)\n",
            "Installing collected packages: JPype1, konlpy\n",
            "Successfully installed JPype1-1.4.0 konlpy-0.6.0\n"
          ]
        }
      ],
      "source": [
        "!python3 -m pip install konlpy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9VvV1TvYz_kO",
        "outputId": "220f07b0-4f0f-4d1e-9e68-1516bd81f2e2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Installing automake (A dependency for mecab-ko)\n",
            "Get:1 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  InRelease [1,581 B]\n",
            "Get:2 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ InRelease [3,626 B]\n",
            "Get:3 https://cloud.r-project.org/bin/linux/ubuntu bionic-cran40/ Packages [85.6 kB]\n",
            "Get:4 http://security.ubuntu.com/ubuntu bionic-security InRelease [88.7 kB]\n",
            "Get:5 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic InRelease [15.9 kB]\n",
            "Ign:6 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  InRelease\n",
            "Get:7 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu1804/x86_64  Packages [824 kB]\n",
            "Hit:8 https://developer.download.nvidia.com/compute/machine-learning/repos/ubuntu1804/x86_64  Release\n",
            "Hit:10 http://archive.ubuntu.com/ubuntu bionic InRelease\n",
            "Get:11 http://archive.ubuntu.com/ubuntu bionic-updates InRelease [88.7 kB]\n",
            "Hit:12 http://ppa.launchpad.net/cran/libgit2/ubuntu bionic InRelease\n",
            "Get:13 http://security.ubuntu.com/ubuntu bionic-security/universe amd64 Packages [1,527 kB]\n",
            "Hit:14 http://ppa.launchpad.net/deadsnakes/ppa/ubuntu bionic InRelease\n",
            "Get:15 http://archive.ubuntu.com/ubuntu bionic-backports InRelease [74.6 kB]\n",
            "Hit:16 http://ppa.launchpad.net/graphics-drivers/ppa/ubuntu bionic InRelease\n",
            "Get:17 http://archive.ubuntu.com/ubuntu bionic-updates/restricted amd64 Packages [1,107 kB]\n",
            "Get:18 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main Sources [2,075 kB]\n",
            "Get:19 http://security.ubuntu.com/ubuntu bionic-security/main amd64 Packages [2,901 kB]\n",
            "Get:20 http://archive.ubuntu.com/ubuntu bionic-updates/main amd64 Packages [3,336 kB]\n",
            "Get:21 http://security.ubuntu.com/ubuntu bionic-security/restricted amd64 Packages [1,063 kB]\n",
            "Get:22 http://archive.ubuntu.com/ubuntu bionic-updates/universe amd64 Packages [2,306 kB]\n",
            "Get:23 http://ppa.launchpad.net/c2d4u.team/c2d4u4.0+/ubuntu bionic/main amd64 Packages [1,063 kB]\n",
            "Fetched 16.6 MB in 5s (3,434 kB/s)\n",
            "Reading package lists... Done\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "The following package was automatically installed and is no longer required:\n",
            "  libnvidia-common-460\n",
            "Use 'sudo apt autoremove' to remove it.\n",
            "The following additional packages will be installed:\n",
            "  autoconf autotools-dev libsigsegv2 m4\n",
            "Suggested packages:\n",
            "  autoconf-archive gnu-standards autoconf-doc libtool gettext m4-doc\n",
            "The following NEW packages will be installed:\n",
            "  autoconf automake autotools-dev libsigsegv2 m4\n",
            "0 upgraded, 5 newly installed, 0 to remove and 71 not upgraded.\n",
            "Need to get 1,082 kB of archives.\n",
            "After this operation, 3,994 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu bionic/main amd64 libsigsegv2 amd64 2.12-1 [14.7 kB]\n",
            "Get:2 http://archive.ubuntu.com/ubuntu bionic/main amd64 m4 amd64 1.4.18-1 [197 kB]\n",
            "Get:3 http://archive.ubuntu.com/ubuntu bionic/main amd64 autoconf all 2.69-11 [322 kB]\n",
            "Get:4 http://archive.ubuntu.com/ubuntu bionic/main amd64 autotools-dev all 20180224.1 [39.6 kB]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu bionic/main amd64 automake all 1:1.15.1-3ubuntu2 [509 kB]\n",
            "Fetched 1,082 kB in 2s (639 kB/s)\n",
            "debconf: unable to initialize frontend: Dialog\n",
            "debconf: (No usable dialog-like program is installed, so the dialog based frontend cannot be used. at /usr/share/perl5/Debconf/FrontEnd/Dialog.pm line 76, <> line 5.)\n",
            "debconf: falling back to frontend: Readline\n",
            "debconf: unable to initialize frontend: Readline\n",
            "debconf: (This frontend requires a controlling tty.)\n",
            "debconf: falling back to frontend: Teletype\n",
            "dpkg-preconfigure: unable to re-open stdin: \n",
            "Selecting previously unselected package libsigsegv2:amd64.\n",
            "(Reading database ... 155653 files and directories currently installed.)\n",
            "Preparing to unpack .../libsigsegv2_2.12-1_amd64.deb ...\n",
            "Unpacking libsigsegv2:amd64 (2.12-1) ...\n",
            "Selecting previously unselected package m4.\n",
            "Preparing to unpack .../archives/m4_1.4.18-1_amd64.deb ...\n",
            "Unpacking m4 (1.4.18-1) ...\n",
            "Selecting previously unselected package autoconf.\n",
            "Preparing to unpack .../autoconf_2.69-11_all.deb ...\n",
            "Unpacking autoconf (2.69-11) ...\n",
            "Selecting previously unselected package autotools-dev.\n",
            "Preparing to unpack .../autotools-dev_20180224.1_all.deb ...\n",
            "Unpacking autotools-dev (20180224.1) ...\n",
            "Selecting previously unselected package automake.\n",
            "Preparing to unpack .../automake_1%3a1.15.1-3ubuntu2_all.deb ...\n",
            "Unpacking automake (1:1.15.1-3ubuntu2) ...\n",
            "Setting up libsigsegv2:amd64 (2.12-1) ...\n",
            "Setting up m4 (1.4.18-1) ...\n",
            "Setting up autotools-dev (20180224.1) ...\n",
            "Setting up autoconf (2.69-11) ...\n",
            "Setting up automake (1:1.15.1-3ubuntu2) ...\n",
            "update-alternatives: using /usr/bin/automake-1.15 to provide /usr/bin/automake (automake) in auto mode\n",
            "Processing triggers for libc-bin (2.27-3ubuntu1.3) ...\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "Processing triggers for man-db (2.8.3-2ubuntu0.1) ...\n",
            "Install mecab-ko\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 1381k  100 1381k    0     0   432k      0  0:00:03  0:00:03 --:--:--  866k\n",
            "mecab-0.996-ko-0.9.2/\n",
            "mecab-0.996-ko-0.9.2/example/\n",
            "mecab-0.996-ko-0.9.2/example/example.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.cpp\n",
            "mecab-0.996-ko-0.9.2/example/example_lattice.c\n",
            "mecab-0.996-ko-0.9.2/example/example.c\n",
            "mecab-0.996-ko-0.9.2/example/thread_test.cpp\n",
            "mecab-0.996-ko-0.9.2/mecab-config.in\n",
            "mecab-0.996-ko-0.9.2/man/\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/man/mecab.1\n",
            "mecab-0.996-ko-0.9.2/man/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/mecab.iss.in\n",
            "mecab-0.996-ko-0.9.2/config.guess\n",
            "mecab-0.996-ko-0.9.2/README\n",
            "mecab-0.996-ko-0.9.2/COPYING\n",
            "mecab-0.996-ko-0.9.2/CHANGES.md\n",
            "mecab-0.996-ko-0.9.2/README.md\n",
            "mecab-0.996-ko-0.9.2/INSTALL\n",
            "mecab-0.996-ko-0.9.2/config.sub\n",
            "mecab-0.996-ko-0.9.2/configure.in\n",
            "mecab-0.996-ko-0.9.2/swig/\n",
            "mecab-0.996-ko-0.9.2/swig/Makefile\n",
            "mecab-0.996-ko-0.9.2/swig/version.h.in\n",
            "mecab-0.996-ko-0.9.2/swig/version.h\n",
            "mecab-0.996-ko-0.9.2/swig/MeCab.i\n",
            "mecab-0.996-ko-0.9.2/aclocal.m4\n",
            "mecab-0.996-ko-0.9.2/LGPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/configure\n",
            "mecab-0.996-ko-0.9.2/tests/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/autolink/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/t9/\n",
            "mecab-0.996-ko-0.9.2/tests/t9/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/ipadic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/t9/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test\n",
            "mecab-0.996-ko-0.9.2/tests/t9/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/t9/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/t9/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.train\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/ipa.test\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/rewrite.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/feature.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/cost-train/seed/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/run-eval.sh\n",
            "mecab-0.996-ko-0.9.2/tests/run-cost-train.sh\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/katakana/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/eval/\n",
            "mecab-0.996-ko-0.9.2/tests/eval/answer\n",
            "mecab-0.996-ko-0.9.2/tests/eval/system\n",
            "mecab-0.996-ko-0.9.2/tests/eval/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/mkdic.pl\n",
            "mecab-0.996-ko-0.9.2/tests/shiin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/latin/\n",
            "mecab-0.996-ko-0.9.2/tests/latin/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/latin/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test\n",
            "mecab-0.996-ko-0.9.2/tests/latin/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/latin/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/chartype/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/run-dics.sh\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/unk.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dicrc\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/dic.csv\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/char.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/matrix.def\n",
            "mecab-0.996-ko-0.9.2/tests/ngram/test.gld\n",
            "mecab-0.996-ko-0.9.2/tests/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/ltmain.sh\n",
            "mecab-0.996-ko-0.9.2/config.rpath\n",
            "mecab-0.996-ko-0.9.2/config.h.in\n",
            "mecab-0.996-ko-0.9.2/mecabrc.in\n",
            "mecab-0.996-ko-0.9.2/GPL\n",
            "mecab-0.996-ko-0.9.2/Makefile.train\n",
            "mecab-0.996-ko-0.9.2/ChangeLog\n",
            "mecab-0.996-ko-0.9.2/install-sh\n",
            "mecab-0.996-ko-0.9.2/AUTHORS\n",
            "mecab-0.996-ko-0.9.2/doc/\n",
            "mecab-0.996-ko-0.9.2/doc/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/posid.html\n",
            "mecab-0.996-ko-0.9.2/doc/unk.html\n",
            "mecab-0.996-ko-0.9.2/doc/learn.html\n",
            "mecab-0.996-ko-0.9.2/doc/format.html\n",
            "mecab-0.996-ko-0.9.2/doc/libmecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.css\n",
            "mecab-0.996-ko-0.9.2/doc/feature.html\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/doc/soft.html\n",
            "mecab-0.996-ko-0.9.2/doc/en/\n",
            "mecab-0.996-ko-0.9.2/doc/en/bindings.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic-detail.html\n",
            "mecab-0.996-ko-0.9.2/doc/flow.png\n",
            "mecab-0.996-ko-0.9.2/doc/mecab.html\n",
            "mecab-0.996-ko-0.9.2/doc/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/result.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_a.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_eval.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_vars.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_r.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Tagger.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h_source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tabs.css\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_f.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/nav_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_h.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/closed.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_l.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/functions_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Lattice-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_func.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers_type.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classMeCab_1_1Model-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__dictionary__info__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaces.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespacemembers.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/namespaceMeCab.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__path__t.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/files.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/structmecab__node__t-members.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/index.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/annotated.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/globals_defs.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/classes.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h-source.html\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/doxygen.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/tab_b.gif\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/bc_s.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/open.png\n",
            "mecab-0.996-ko-0.9.2/doc/doxygen/mecab_8h.html\n",
            "mecab-0.996-ko-0.9.2/doc/dic.html\n",
            "mecab-0.996-ko-0.9.2/doc/partial.html\n",
            "mecab-0.996-ko-0.9.2/doc/feature.png\n",
            "mecab-0.996-ko-0.9.2/doc/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/missing\n",
            "mecab-0.996-ko-0.9.2/BSD\n",
            "mecab-0.996-ko-0.9.2/NEWS\n",
            "mecab-0.996-ko-0.9.2/mkinstalldirs\n",
            "mecab-0.996-ko-0.9.2/src/\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.h\n",
            "mecab-0.996-ko-0.9.2/src/utils.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/make.bat\n",
            "mecab-0.996-ko-0.9.2/src/mecab.h\n",
            "mecab-0.996-ko-0.9.2/src/freelist.h\n",
            "mecab-0.996-ko-0.9.2/src/string_buffer.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_compiler.cpp\n",
            "mecab-0.996-ko-0.9.2/src/eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-system-eval.cpp\n",
            "mecab-0.996-ko-0.9.2/src/darts.h\n",
            "mecab-0.996-ko-0.9.2/src/param.h\n",
            "mecab-0.996-ko-0.9.2/src/char_property.h\n",
            "mecab-0.996-ko-0.9.2/src/learner_node.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-dict-index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/winmain.h\n",
            "mecab-0.996-ko-0.9.2/src/thread.h\n",
            "mecab-0.996-ko-0.9.2/src/context_id.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.am\n",
            "mecab-0.996-ko-0.9.2/src/connector.h\n",
            "mecab-0.996-ko-0.9.2/src/common.h\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.msvc.in\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_rewriter.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.h\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/char_property.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-test-gen.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/mecab-cost-train.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.cpp\n",
            "mecab-0.996-ko-0.9.2/src/ucs.h\n",
            "mecab-0.996-ko-0.9.2/src/writer.cpp\n",
            "mecab-0.996-ko-0.9.2/src/learner_tagger.cpp\n",
            "mecab-0.996-ko-0.9.2/src/lbfgs.h\n",
            "mecab-0.996-ko-0.9.2/src/libmecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/tokenizer.h\n",
            "mecab-0.996-ko-0.9.2/src/mecab.cpp\n",
            "mecab-0.996-ko-0.9.2/src/utils.cpp\n",
            "mecab-0.996-ko-0.9.2/src/dictionary_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/param.cpp\n",
            "mecab-0.996-ko-0.9.2/src/context_id.h\n",
            "mecab-0.996-ko-0.9.2/src/mmap.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.h\n",
            "mecab-0.996-ko-0.9.2/src/viterbi.cpp\n",
            "mecab-0.996-ko-0.9.2/src/stream_wrapper.h\n",
            "mecab-0.996-ko-0.9.2/src/feature_index.cpp\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.h\n",
            "mecab-0.996-ko-0.9.2/src/ucstable.h\n",
            "mecab-0.996-ko-0.9.2/src/nbest_generator.cpp\n",
            "mecab-0.996-ko-0.9.2/src/iconv_utils.h\n",
            "mecab-0.996-ko-0.9.2/src/connector.cpp\n",
            "mecab-0.996-ko-0.9.2/src/Makefile.in\n",
            "mecab-0.996-ko-0.9.2/src/scoped_ptr.h\n",
            "mecab-0.996-ko-0.9.2/Makefile.in\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking for gcc... gcc\n",
            "checking whether the C compiler works... yes\n",
            "checking for C compiler default output file name... a.out\n",
            "checking for suffix of executables... \n",
            "checking whether we are cross compiling... no\n",
            "checking for suffix of object files... o\n",
            "checking whether we are using the GNU C compiler... yes\n",
            "checking whether gcc accepts -g... yes\n",
            "checking for gcc option to accept ISO C89... none needed\n",
            "checking for style of include used by make... GNU\n",
            "checking dependency style of gcc... none\n",
            "checking for g++... g++\n",
            "checking whether we are using the GNU C++ compiler... yes\n",
            "checking whether g++ accepts -g... yes\n",
            "checking dependency style of g++... none\n",
            "checking how to run the C preprocessor... gcc -E\n",
            "checking for grep that handles long lines and -e... /bin/grep\n",
            "checking for egrep... /bin/grep -E\n",
            "checking whether gcc needs -traditional... no\n",
            "checking whether make sets $(MAKE)... (cached) yes\n",
            "checking build system type... x86_64-unknown-linux-gnu\n",
            "checking host system type... x86_64-unknown-linux-gnu\n",
            "checking how to print strings... printf\n",
            "checking for a sed that does not truncate output... /bin/sed\n",
            "checking for fgrep... /bin/grep -F\n",
            "checking for ld used by gcc... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for BSD- or MS-compatible name lister (nm)... /usr/bin/nm -B\n",
            "checking the name lister (/usr/bin/nm -B) interface... BSD nm\n",
            "checking whether ln -s works... yes\n",
            "checking the maximum length of command line arguments... 1572864\n",
            "checking whether the shell understands some XSI constructs... yes\n",
            "checking whether the shell understands \"+=\"... yes\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to x86_64-unknown-linux-gnu format... func_convert_file_noop\n",
            "checking how to convert x86_64-unknown-linux-gnu file names to toolchain format... func_convert_file_noop\n",
            "checking for /usr/bin/ld option to reload object files... -r\n",
            "checking for objdump... objdump\n",
            "checking how to recognize dependent libraries... pass_all\n",
            "checking for dlltool... dlltool\n",
            "checking how to associate runtime and link libraries... printf %s\\n\n",
            "checking for ar... ar\n",
            "checking for archiver @FILE support... @\n",
            "checking for strip... strip\n",
            "checking for ranlib... ranlib\n",
            "checking command to parse /usr/bin/nm -B output from gcc object... ok\n",
            "checking for sysroot... no\n",
            "./configure: line 7378: /usr/bin/file: No such file or directory\n",
            "checking for mt... no\n",
            "checking if : is a manifest tool... no\n",
            "checking for ANSI C header files... yes\n",
            "checking for sys/types.h... yes\n",
            "checking for sys/stat.h... yes\n",
            "checking for stdlib.h... yes\n",
            "checking for string.h... yes\n",
            "checking for memory.h... yes\n",
            "checking for strings.h... yes\n",
            "checking for inttypes.h... yes\n",
            "checking for stdint.h... yes\n",
            "checking for unistd.h... yes\n",
            "checking for dlfcn.h... yes\n",
            "checking for objdir... .libs\n",
            "checking if gcc supports -fno-rtti -fno-exceptions... no\n",
            "checking for gcc option to produce PIC... -fPIC -DPIC\n",
            "checking if gcc PIC flag -fPIC -DPIC works... yes\n",
            "checking if gcc static flag -static works... yes\n",
            "checking if gcc supports -c -o file.o... yes\n",
            "checking if gcc supports -c -o file.o... (cached) yes\n",
            "checking whether the gcc linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking whether -lc should be explicitly linked in... no\n",
            "checking dynamic linker characteristics... GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking whether stripping libraries is possible... yes\n",
            "checking if libtool supports shared libraries... yes\n",
            "checking whether to build shared libraries... yes\n",
            "checking whether to build static libraries... yes\n",
            "checking how to run the C++ preprocessor... g++ -E\n",
            "checking for ld used by g++... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking for g++ option to produce PIC... -fPIC -DPIC\n",
            "checking if g++ PIC flag -fPIC -DPIC works... yes\n",
            "checking if g++ static flag -static works... yes\n",
            "checking if g++ supports -c -o file.o... yes\n",
            "checking if g++ supports -c -o file.o... (cached) yes\n",
            "checking whether the g++ linker (/usr/bin/ld) supports shared libraries... yes\n",
            "checking dynamic linker characteristics... (cached) GNU/Linux ld.so\n",
            "checking how to hardcode library paths into programs... immediate\n",
            "checking for library containing strerror... none required\n",
            "checking whether byte ordering is bigendian... no\n",
            "checking for ld used by GCC... /usr/bin/ld\n",
            "checking if the linker (/usr/bin/ld) is GNU ld... yes\n",
            "checking for shared library run path origin... done\n",
            "checking for iconv... yes\n",
            "checking for working iconv... yes\n",
            "checking for iconv declaration... \n",
            "         extern size_t iconv (iconv_t cd, char * *inbuf, size_t *inbytesleft, char * *outbuf, size_t *outbytesleft);\n",
            "checking for ANSI C header files... (cached) yes\n",
            "checking for an ANSI C-conforming const... yes\n",
            "checking whether byte ordering is bigendian... (cached) no\n",
            "checking for string.h... (cached) yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking fcntl.h usability... yes\n",
            "checking fcntl.h presence... yes\n",
            "checking for fcntl.h... yes\n",
            "checking for stdint.h... (cached) yes\n",
            "checking for sys/stat.h... (cached) yes\n",
            "checking sys/mman.h usability... yes\n",
            "checking sys/mman.h presence... yes\n",
            "checking for sys/mman.h... yes\n",
            "checking sys/times.h usability... yes\n",
            "checking sys/times.h presence... yes\n",
            "checking for sys/times.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking dirent.h usability... yes\n",
            "checking dirent.h presence... yes\n",
            "checking for dirent.h... yes\n",
            "checking ctype.h usability... yes\n",
            "checking ctype.h presence... yes\n",
            "checking for ctype.h... yes\n",
            "checking for sys/types.h... (cached) yes\n",
            "checking io.h usability... no\n",
            "checking io.h presence... no\n",
            "checking for io.h... no\n",
            "checking windows.h usability... no\n",
            "checking windows.h presence... no\n",
            "checking for windows.h... no\n",
            "checking pthread.h usability... yes\n",
            "checking pthread.h presence... yes\n",
            "checking for pthread.h... yes\n",
            "checking for off_t... yes\n",
            "checking for size_t... yes\n",
            "checking size of char... 1\n",
            "checking size of short... 2\n",
            "checking size of int... 4\n",
            "checking size of long... 8\n",
            "checking size of long long... 8\n",
            "checking size of size_t... 8\n",
            "checking for size_t... (cached) yes\n",
            "checking for unsigned long long int... yes\n",
            "checking for stdlib.h... (cached) yes\n",
            "checking for unistd.h... (cached) yes\n",
            "checking for sys/param.h... yes\n",
            "checking for getpagesize... yes\n",
            "checking for working mmap... yes\n",
            "checking for main in -lstdc++... yes\n",
            "checking for pthread_create in -lpthread... yes\n",
            "checking for pthread_join in -lpthread... yes\n",
            "checking for getenv... yes\n",
            "checking for opendir... yes\n",
            "checking whether make is GNU Make... yes\n",
            "checking if g++ supports stl <vector> (required)... yes\n",
            "checking if g++ supports stl <list> (required)... yes\n",
            "checking if g++ supports stl <map> (required)... yes\n",
            "checking if g++ supports stl <set> (required)... yes\n",
            "checking if g++ supports stl <queue> (required)... yes\n",
            "checking if g++ supports stl <functional> (required)... yes\n",
            "checking if g++ supports stl <algorithm> (required)... yes\n",
            "checking if g++ supports stl <string> (required)... yes\n",
            "checking if g++ supports stl <iostream> (required)... yes\n",
            "checking if g++ supports stl <sstream> (required)... yes\n",
            "checking if g++ supports stl <fstream> (required)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports const_cast<> (required)... yes\n",
            "checking if g++ supports static_cast<> (required)... yes\n",
            "checking if g++ supports reinterpret_cast<> (required)... yes\n",
            "checking if g++ supports namespaces (required) ... yes\n",
            "checking if g++ supports __thread (optional)... yes\n",
            "checking if g++ supports template <class T> (required)... yes\n",
            "checking if g++ supports GCC native atomic operations (optional)... yes\n",
            "checking if g++ supports OSX native atomic operations (optional)... no\n",
            "checking if g++ environment provides all required features... yes\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "config.status: creating src/Makefile\n",
            "config.status: creating src/Makefile.msvc\n",
            "config.status: creating man/Makefile\n",
            "config.status: creating doc/Makefile\n",
            "config.status: creating tests/Makefile\n",
            "config.status: creating swig/version.h\n",
            "config.status: creating mecab.iss\n",
            "config.status: creating mecab-config\n",
            "config.status: creating mecabrc\n",
            "config.status: creating config.h\n",
            "config.status: executing depfiles commands\n",
            "config.status: executing libtool commands\n",
            "config.status: executing default commands\n",
            "make  all-recursive\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making all in src\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o viterbi.lo viterbi.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp  -fPIC -DPIC -o .libs/viterbi.o\n",
            "In file included from \u001b[01m\u001b[Kviterbi.cpp:14:0\u001b[m\u001b[K:\n",
            "\u001b[01m\u001b[Kparam.h:30:13:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[KTarget {anonymous}::lexical_cast(Source) [with Target = std::__cxx11::basic_string<char>; Source = std::__cxx11::basic_string<char>]\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " std::string \u001b[01;35m\u001b[Klexical_cast<std::string, std::string>\u001b[m\u001b[K(std::string arg) {\n",
            "             \u001b[01;35m\u001b[K^~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c viterbi.cpp -o viterbi.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tagger.lo tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp  -fPIC -DPIC -o .libs/tagger.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tagger.cpp -o tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o utils.lo utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp  -fPIC -DPIC -o .libs/utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c utils.cpp -o utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o eval.lo eval.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp  -fPIC -DPIC -o .libs/eval.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c eval.cpp -o eval.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o iconv_utils.lo iconv_utils.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp  -fPIC -DPIC -o .libs/iconv_utils.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c iconv_utils.cpp -o iconv_utils.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_rewriter.lo dictionary_rewriter.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp  -fPIC -DPIC -o .libs/dictionary_rewriter.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_rewriter.cpp -o dictionary_rewriter.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_generator.lo dictionary_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp  -fPIC -DPIC -o .libs/dictionary_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_generator.cpp -o dictionary_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary_compiler.lo dictionary_compiler.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp  -fPIC -DPIC -o .libs/dictionary_compiler.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary_compiler.cpp -o dictionary_compiler.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o context_id.lo context_id.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp  -fPIC -DPIC -o .libs/context_id.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c context_id.cpp -o context_id.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o connector.lo connector.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp  -fPIC -DPIC -o .libs/connector.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c connector.cpp -o connector.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o nbest_generator.lo nbest_generator.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp  -fPIC -DPIC -o .libs/nbest_generator.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c nbest_generator.cpp -o nbest_generator.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o writer.lo writer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp  -fPIC -DPIC -o .libs/writer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c writer.cpp -o writer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o string_buffer.lo string_buffer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp  -fPIC -DPIC -o .libs/string_buffer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c string_buffer.cpp -o string_buffer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o param.lo param.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp  -fPIC -DPIC -o .libs/param.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c param.cpp -o param.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o tokenizer.lo tokenizer.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp  -fPIC -DPIC -o .libs/tokenizer.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c tokenizer.cpp -o tokenizer.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o char_property.lo char_property.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp  -fPIC -DPIC -o .libs/char_property.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c char_property.cpp -o char_property.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o dictionary.lo dictionary.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp  -fPIC -DPIC -o .libs/dictionary.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c dictionary.cpp -o dictionary.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o feature_index.lo feature_index.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp  -fPIC -DPIC -o .libs/feature_index.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c feature_index.cpp -o feature_index.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o lbfgs.lo lbfgs.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp  -fPIC -DPIC -o .libs/lbfgs.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c lbfgs.cpp -o lbfgs.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner_tagger.lo learner_tagger.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp  -fPIC -DPIC -o .libs/learner_tagger.o\n",
            "\u001b[01m\u001b[Klearner_tagger.cpp:25:7:\u001b[m\u001b[K \u001b[01;35m\u001b[Kwarning: \u001b[m\u001b[K'\u001b[01m\u001b[Kchar* MeCab::{anonymous}::mystrdup(const string&)\u001b[m\u001b[K' defined but not used [\u001b[01;35m\u001b[K-Wunused-function\u001b[m\u001b[K]\n",
            " char *\u001b[01;35m\u001b[Kmystrdup\u001b[m\u001b[K(const std::string &str) {\n",
            "       \u001b[01;35m\u001b[K^~~~~~~~\u001b[m\u001b[K\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner_tagger.cpp -o learner_tagger.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o learner.lo learner.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp  -fPIC -DPIC -o .libs/learner.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c learner.cpp -o learner.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=compile g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o libmecab.lo libmecab.cpp\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp  -fPIC -DPIC -o .libs/libmecab.o\n",
            "libtool: compile:  g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102 -DMECAB_DEFAULT_RC=\\\"/usr/local/etc/mecabrc\\\" -O3 -Wall -c libmecab.cpp -o libmecab.o >/dev/null 2>&1\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall  -no-undefined -version-info 2:0:0  -o libmecab.la -rpath /usr/local/lib viterbi.lo tagger.lo utils.lo eval.lo iconv_utils.lo dictionary_rewriter.lo dictionary_generator.lo dictionary_compiler.lo context_id.lo connector.lo nbest_generator.lo writer.lo string_buffer.lo param.lo tokenizer.lo char_property.lo dictionary.lo feature_index.lo lbfgs.lo learner_tagger.lo learner.lo libmecab.lo  -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++  -fPIC -DPIC -shared -nostdlib /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crti.o /usr/lib/gcc/x86_64-linux-gnu/7/crtbeginS.o  .libs/viterbi.o .libs/tagger.o .libs/utils.o .libs/eval.o .libs/iconv_utils.o .libs/dictionary_rewriter.o .libs/dictionary_generator.o .libs/dictionary_compiler.o .libs/context_id.o .libs/connector.o .libs/nbest_generator.o .libs/writer.o .libs/string_buffer.o .libs/param.o .libs/tokenizer.o .libs/char_property.o .libs/dictionary.o .libs/feature_index.o .libs/lbfgs.o .libs/learner_tagger.o .libs/learner.o .libs/libmecab.o   -lpthread -L/usr/lib/gcc/x86_64-linux-gnu/7 -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu -L/usr/lib/gcc/x86_64-linux-gnu/7/../../../../lib -L/lib/x86_64-linux-gnu -L/lib/../lib -L/usr/lib/x86_64-linux-gnu -L/usr/lib/../lib -L/usr/local/cuda/lib64/stubs -L/usr/lib/gcc/x86_64-linux-gnu/7/../../.. -lstdc++ -lm -lc -lgcc_s /usr/lib/gcc/x86_64-linux-gnu/7/crtendS.o /usr/lib/gcc/x86_64-linux-gnu/7/../../../x86_64-linux-gnu/crtn.o  -O3   -Wl,-soname -Wl,libmecab.so.2 -o .libs/libmecab.so.2.0.0\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so.2\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so.2\")\n",
            "libtool: link: (cd \".libs\" && rm -f \"libmecab.so\" && ln -s \"libmecab.so.2.0.0\" \"libmecab.so\")\n",
            "libtool: link: ar cru .libs/libmecab.a  viterbi.o tagger.o utils.o eval.o iconv_utils.o dictionary_rewriter.o dictionary_generator.o dictionary_compiler.o context_id.o connector.o nbest_generator.o writer.o string_buffer.o param.o tokenizer.o char_property.o dictionary.o feature_index.o lbfgs.o learner_tagger.o learner.o libmecab.o\n",
            "ar: `u' modifier ignored since `D' is the default (see `U')\n",
            "libtool: link: ranlib .libs/libmecab.a\n",
            "libtool: link: ( cd \".libs\" && rm -f \"libmecab.la\" && ln -s \"../libmecab.la\" \"libmecab.la\" )\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab.o mecab.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab mecab.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab mecab.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-index.o mecab-dict-index.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-index mecab-dict-index.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-index mecab-dict-index.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-dict-gen.o mecab-dict-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-dict-gen mecab-dict-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-dict-gen mecab-dict-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-cost-train.o mecab-cost-train.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-cost-train mecab-cost-train.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-cost-train mecab-cost-train.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-system-eval.o mecab-system-eval.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-system-eval mecab-system-eval.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-system-eval mecab-system-eval.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "g++ -DHAVE_CONFIG_H -I. -I.. -DDIC_VERSION=102   -DMECAB_DEFAULT_RC=\"\\\"/usr/local/etc/mecabrc\\\"\"    -O3 -Wall  -c -o mecab-test-gen.o mecab-test-gen.cpp\n",
            "/bin/bash ../libtool --tag=CXX   --mode=link g++  -O3 -Wall    -o mecab-test-gen mecab-test-gen.o libmecab.la -lpthread -lpthread  -lstdc++ \n",
            "libtool: link: g++ -O3 -Wall -o .libs/mecab-test-gen mecab-test-gen.o  ./.libs/libmecab.so -lpthread -lstdc++\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making all in man\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making all in doc\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making all in tests\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'all'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making check in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making check in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making check in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Nothing to be done for 'check'.\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making check in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make  check-TESTS\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 177\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 178x178\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 83\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 84x84\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 450\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 162\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3x3\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 4\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 11\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./unk.def ... 2\n",
            "emitting double-array: 100% |###########################################| \n",
            "./model.def is not found. skipped.\n",
            "./pos-id.def is not found. minimum setting is used\n",
            "reading ./dic.csv ... 1\n",
            "reading ./matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "PASS: run-dics.sh\n",
            "PASS: run-eval.sh\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "seed/model.def is not found. skipped.\n",
            "seed/pos-id.def is not found. minimum setting is used\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading seed/matrix.def ... 1x1\n",
            "\n",
            "done!\n",
            "reading corpus ...\n",
            "Number of sentences: 34\n",
            "Number of features:  64108\n",
            "eta:                 0.00005\n",
            "freq:                1\n",
            "eval-size:           6\n",
            "unk-eval-size:       4\n",
            "threads:             1\n",
            "charset:             EUC-JP\n",
            "C(sigma^2):          1.00000\n",
            "\n",
            "iter=0 err=1.00000 F=0.35771 target=2406.28355 diff=1.00000\n",
            "iter=1 err=0.97059 F=0.65652 target=1484.25231 diff=0.38318\n",
            "iter=2 err=0.91176 F=0.79331 target=863.32765 diff=0.41834\n",
            "iter=3 err=0.85294 F=0.89213 target=596.72480 diff=0.30881\n",
            "iter=4 err=0.61765 F=0.95467 target=336.30744 diff=0.43641\n",
            "iter=5 err=0.50000 F=0.96702 target=246.53039 diff=0.26695\n",
            "iter=6 err=0.35294 F=0.95472 target=188.93963 diff=0.23361\n",
            "iter=7 err=0.20588 F=0.99106 target=168.62665 diff=0.10751\n",
            "iter=8 err=0.05882 F=0.99777 target=158.64865 diff=0.05917\n",
            "iter=9 err=0.08824 F=0.99665 target=154.14530 diff=0.02839\n",
            "iter=10 err=0.08824 F=0.99665 target=151.94257 diff=0.01429\n",
            "iter=11 err=0.02941 F=0.99888 target=147.20825 diff=0.03116\n",
            "iter=12 err=0.00000 F=1.00000 target=147.34956 diff=0.00096\n",
            "iter=13 err=0.02941 F=0.99888 target=146.32592 diff=0.00695\n",
            "iter=14 err=0.00000 F=1.00000 target=145.77299 diff=0.00378\n",
            "iter=15 err=0.02941 F=0.99888 target=145.24641 diff=0.00361\n",
            "iter=16 err=0.00000 F=1.00000 target=144.96490 diff=0.00194\n",
            "iter=17 err=0.02941 F=0.99888 target=144.90246 diff=0.00043\n",
            "iter=18 err=0.00000 F=1.00000 target=144.75959 diff=0.00099\n",
            "iter=19 err=0.00000 F=1.00000 target=144.71727 diff=0.00029\n",
            "iter=20 err=0.00000 F=1.00000 target=144.66337 diff=0.00037\n",
            "iter=21 err=0.00000 F=1.00000 target=144.61349 diff=0.00034\n",
            "iter=22 err=0.00000 F=1.00000 target=144.62987 diff=0.00011\n",
            "iter=23 err=0.00000 F=1.00000 target=144.60060 diff=0.00020\n",
            "iter=24 err=0.00000 F=1.00000 target=144.59125 diff=0.00006\n",
            "iter=25 err=0.00000 F=1.00000 target=144.58619 diff=0.00004\n",
            "iter=26 err=0.00000 F=1.00000 target=144.58219 diff=0.00003\n",
            "iter=27 err=0.00000 F=1.00000 target=144.58059 diff=0.00001\n",
            "\n",
            "Done! writing model file ... \n",
            "model-ipadic.c1.0.f1.model is not a binary model. reopen it as text mode...\n",
            "reading seed/unk.def ... 40\n",
            "reading seed/dic.csv ... 4335\n",
            "emitting model-ipadic.c1.0.f1.dic/left-id.def/ model-ipadic.c1.0.f1.dic/right-id.def\n",
            "emitting model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting matrix      : 100% |###########################################| \n",
            "copying seed/char.def to model-ipadic.c1.0.f1.dic/char.def\n",
            "copying seed/rewrite.def to model-ipadic.c1.0.f1.dic/rewrite.def\n",
            "copying seed/dicrc to model-ipadic.c1.0.f1.dic/dicrc\n",
            "copying seed/feature.def to model-ipadic.c1.0.f1.dic/feature.def\n",
            "copying model-ipadic.c1.0.f1.model to model-ipadic.c1.0.f1.dic/model.def\n",
            "\n",
            "done!\n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/unk.def ... 40\n",
            "emitting double-array: 100% |###########################################| \n",
            "model-ipadic.c1.0.f1.dic/pos-id.def is not found. minimum setting is used\n",
            "reading model-ipadic.c1.0.f1.dic/dic.csv ... 4335\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading model-ipadic.c1.0.f1.dic/matrix.def ... 346x346\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "              precision          recall         F\n",
            "LEVEL 0:    12.8959(57/442) 11.8998(57/479) 12.3779\n",
            "LEVEL 1:    12.2172(54/442) 11.2735(54/479) 11.7264\n",
            "LEVEL 2:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "LEVEL 4:    11.7647(52/442) 10.8559(52/479) 11.2921\n",
            "PASS: run-cost-train.sh\n",
            "==================\n",
            "All 3 tests passed\n",
            "==================\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Making install in src\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "test -z \"/usr/local/lib\" || /bin/mkdir -p \"/usr/local/lib\"\n",
            " /bin/bash ../libtool   --mode=install /usr/bin/install -c   libmecab.la '/usr/local/lib'\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.so.2.0.0 /usr/local/lib/libmecab.so.2.0.0\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so.2 || { rm -f libmecab.so.2 && ln -s libmecab.so.2.0.0 libmecab.so.2; }; })\n",
            "libtool: install: (cd /usr/local/lib && { ln -s -f libmecab.so.2.0.0 libmecab.so || { rm -f libmecab.so && ln -s libmecab.so.2.0.0 libmecab.so; }; })\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.lai /usr/local/lib/libmecab.la\n",
            "libtool: install: /usr/bin/install -c .libs/libmecab.a /usr/local/lib/libmecab.a\n",
            "libtool: install: chmod 644 /usr/local/lib/libmecab.a\n",
            "libtool: install: ranlib /usr/local/lib/libmecab.a\n",
            "libtool: finish: PATH=\"/usr/local/sbin:/usr/local/bin:/usr/sbin:/usr/bin:/sbin:/bin:/snap/bin:/sbin\" ldconfig -n /usr/local/lib\n",
            "----------------------------------------------------------------------\n",
            "Libraries have been installed in:\n",
            "   /usr/local/lib\n",
            "\n",
            "If you ever happen to want to link against installed libraries\n",
            "in a given directory, LIBDIR, you must either use libtool, and\n",
            "specify the full pathname of the library, or use the `-LLIBDIR'\n",
            "flag during linking and do at least one of the following:\n",
            "   - add LIBDIR to the `LD_LIBRARY_PATH' environment variable\n",
            "     during execution\n",
            "   - add LIBDIR to the `LD_RUN_PATH' environment variable\n",
            "     during linking\n",
            "   - use the `-Wl,-rpath -Wl,LIBDIR' linker flag\n",
            "   - have your system administrator add LIBDIR to `/etc/ld.so.conf'\n",
            "\n",
            "See any operating system documentation about shared libraries for\n",
            "more information, such as the ld(1) and ld.so(8) manual pages.\n",
            "----------------------------------------------------------------------\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab '/usr/local/bin'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab /usr/local/bin/mecab\n",
            "test -z \"/usr/local/libexec/mecab\" || /bin/mkdir -p \"/usr/local/libexec/mecab\"\n",
            "  /bin/bash ../libtool   --mode=install /usr/bin/install -c mecab-dict-index mecab-dict-gen mecab-cost-train mecab-system-eval mecab-test-gen '/usr/local/libexec/mecab'\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-index /usr/local/libexec/mecab/mecab-dict-index\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-dict-gen /usr/local/libexec/mecab/mecab-dict-gen\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-cost-train /usr/local/libexec/mecab/mecab-cost-train\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-system-eval /usr/local/libexec/mecab/mecab-system-eval\n",
            "libtool: install: /usr/bin/install -c .libs/mecab-test-gen /usr/local/libexec/mecab/mecab-test-gen\n",
            "test -z \"/usr/local/include\" || /bin/mkdir -p \"/usr/local/include\"\n",
            " /usr/bin/install -c -m 644 mecab.h '/usr/local/include'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/src'\n",
            "Making install in man\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "test -z \"/usr/local/share/man/man1\" || /bin/mkdir -p \"/usr/local/share/man/man1\"\n",
            " /usr/bin/install -c -m 644 mecab.1 '/usr/local/share/man/man1'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/man'\n",
            "Making install in doc\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/doc'\n",
            "Making install in tests\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[2]: Nothing to be done for 'install-exec-am'.\n",
            "make[2]: Nothing to be done for 'install-data-am'.\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2/tests'\n",
            "make[1]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[2]: Entering directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "test -z \"/usr/local/bin\" || /bin/mkdir -p \"/usr/local/bin\"\n",
            " /usr/bin/install -c mecab-config '/usr/local/bin'\n",
            "test -z \"/usr/local/etc\" || /bin/mkdir -p \"/usr/local/etc\"\n",
            " /usr/bin/install -c -m 644 mecabrc '/usr/local/etc'\n",
            "make[2]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "make[1]: Leaving directory '/tmp/mecab-0.996-ko-0.9.2'\n",
            "Install mecab-ko-dic\n",
            "Install mecab-ko-dic\n",
            "  % Total    % Received % Xferd  Average Speed   Time    Time     Time  Current\n",
            "                                 Dload  Upload   Total   Spent    Left  Speed\n",
            "  0     0    0     0    0     0      0      0 --:--:-- --:--:-- --:--:--     0\n",
            "100 47.4M  100 47.4M    0     0  6939k      0  0:00:07  0:00:07 --:--:--  9.8M\n",
            "mecab-ko-dic-2.1.1-20180720/\n",
            "mecab-ko-dic-2.1.1-20180720/configure\n",
            "mecab-ko-dic-2.1.1-20180720/COPYING\n",
            "mecab-ko-dic-2.1.1-20180720/autogen.sh\n",
            "mecab-ko-dic-2.1.1-20180720/Place-station.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/README\n",
            "mecab-ko-dic-2.1.1-20180720/EF.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAG.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Preanalysis.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNB.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Person-actor.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.in\n",
            "mecab-ko-dic-2.1.1-20180720/matrix.def\n",
            "mecab-ko-dic-2.1.1-20180720/EC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NNBC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/clean\n",
            "mecab-ko-dic-2.1.1-20180720/ChangeLog\n",
            "mecab-ko-dic-2.1.1-20180720/J.csv\n",
            "mecab-ko-dic-2.1.1-20180720/.keep\n",
            "mecab-ko-dic-2.1.1-20180720/feature.def\n",
            "mecab-ko-dic-2.1.1-20180720/Foreign.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XPN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/EP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/NR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/left-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Symbol.csv\n",
            "mecab-ko-dic-2.1.1-20180720/dicrc\n",
            "mecab-ko-dic-2.1.1-20180720/NP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/IC.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Place-address.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Group.csv\n",
            "mecab-ko-dic-2.1.1-20180720/model.def\n",
            "mecab-ko-dic-2.1.1-20180720/XSN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/INSTALL\n",
            "mecab-ko-dic-2.1.1-20180720/rewrite.def\n",
            "mecab-ko-dic-2.1.1-20180720/Inflect.csv\n",
            "mecab-ko-dic-2.1.1-20180720/configure.ac\n",
            "mecab-ko-dic-2.1.1-20180720/NNP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/CoinedWord.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSV.csv\n",
            "mecab-ko-dic-2.1.1-20180720/pos-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/Makefile.am\n",
            "mecab-ko-dic-2.1.1-20180720/unk.def\n",
            "mecab-ko-dic-2.1.1-20180720/missing\n",
            "mecab-ko-dic-2.1.1-20180720/VCP.csv\n",
            "mecab-ko-dic-2.1.1-20180720/install-sh\n",
            "mecab-ko-dic-2.1.1-20180720/Hanja.csv\n",
            "mecab-ko-dic-2.1.1-20180720/MAJ.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XSA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/Wikipedia.csv\n",
            "mecab-ko-dic-2.1.1-20180720/tools/\n",
            "mecab-ko-dic-2.1.1-20180720/tools/add-userdic.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/mecab-bestn.sh\n",
            "mecab-ko-dic-2.1.1-20180720/tools/convert_for_using_store.sh\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/nnp.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/place.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/user-dic/README.md\n",
            "mecab-ko-dic-2.1.1-20180720/NorthKorea.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VX.csv\n",
            "mecab-ko-dic-2.1.1-20180720/right-id.def\n",
            "mecab-ko-dic-2.1.1-20180720/VA.csv\n",
            "mecab-ko-dic-2.1.1-20180720/char.def\n",
            "mecab-ko-dic-2.1.1-20180720/NEWS\n",
            "mecab-ko-dic-2.1.1-20180720/MM.csv\n",
            "mecab-ko-dic-2.1.1-20180720/ETN.csv\n",
            "mecab-ko-dic-2.1.1-20180720/AUTHORS\n",
            "mecab-ko-dic-2.1.1-20180720/Person.csv\n",
            "mecab-ko-dic-2.1.1-20180720/XR.csv\n",
            "mecab-ko-dic-2.1.1-20180720/VCN.csv\n",
            "Looking in current directory for macros.\n",
            "configure.ac:2: warning: AM_INIT_AUTOMAKE: two- and three-arguments forms are deprecated.  For more info, see:\n",
            "configure.ac:2: http://www.gnu.org/software/automake/manual/automake.html#Modernize-AM_005fINIT_005fAUTOMAKE-invocation\n",
            "checking for a BSD-compatible install... /usr/bin/install -c\n",
            "checking whether build environment is sane... yes\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720/missing: Unknown `--is-lightweight' option\n",
            "Try `/tmp/mecab-ko-dic-2.1.1-20180720/missing --help' for more information\n",
            "configure: WARNING: 'missing' script is too old or missing\n",
            "checking for a thread-safe mkdir -p... /bin/mkdir -p\n",
            "checking for gawk... no\n",
            "checking for mawk... mawk\n",
            "checking whether make sets $(MAKE)... yes\n",
            "checking whether make supports nested variables... yes\n",
            "checking for mecab-config... /usr/local/bin/mecab-config\n",
            "checking that generated files are newer than configure... done\n",
            "configure: creating ./config.status\n",
            "config.status: creating Makefile\n",
            "/usr/local/lib\n",
            "/sbin/ldconfig.real: /usr/local/lib/python3.7/dist-packages/ideep4py/lib/libmkldnn.so.0 is not a symbolic link\n",
            "\n",
            "/usr/local/libexec/mecab/mecab-dict-index -d . -o . -f UTF-8 -t UTF-8\n",
            "reading ./unk.def ... 13\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./XR.csv ... 3637\n",
            "reading ./XPN.csv ... 83\n",
            "reading ./Person-actor.csv ... 99230\n",
            "reading ./Place.csv ... 30303\n",
            "reading ./EC.csv ... 2547\n",
            "reading ./MAG.csv ... 14242\n",
            "reading ./Person.csv ... 196459\n",
            "reading ./Inflect.csv ... 44820\n",
            "reading ./J.csv ... 416\n",
            "reading ./NR.csv ... 482\n",
            "reading ./EP.csv ... 51\n",
            "reading ./ETN.csv ... 14\n",
            "reading ./Hanja.csv ... 125750\n",
            "reading ./VX.csv ... 125\n",
            "reading ./NNB.csv ... 140\n",
            "reading ./VV.csv ... 7331\n",
            "reading ./NorthKorea.csv ... 3\n",
            "reading ./VCP.csv ... 9\n",
            "reading ./IC.csv ... 1305\n",
            "reading ./VCN.csv ... 7\n",
            "reading ./Symbol.csv ... 16\n",
            "reading ./Wikipedia.csv ... 36762\n",
            "reading ./EF.csv ... 1820\n",
            "reading ./Preanalysis.csv ... 5\n",
            "reading ./NNP.csv ... 2371\n",
            "reading ./VA.csv ... 2360\n",
            "reading ./MM.csv ... 453\n",
            "reading ./CoinedWord.csv ... 148\n",
            "reading ./NP.csv ... 342\n",
            "reading ./XSV.csv ... 23\n",
            "reading ./NNBC.csv ... 677\n",
            "reading ./Group.csv ... 3176\n",
            "reading ./XSA.csv ... 19\n",
            "reading ./NNG.csv ... 208524\n",
            "reading ./Place-address.csv ... 19301\n",
            "reading ./MAJ.csv ... 240\n",
            "reading ./Place-station.csv ... 1145\n",
            "reading ./Foreign.csv ... 11690\n",
            "reading ./ETM.csv ... 133\n",
            "reading ./XSN.csv ... 124\n",
            "emitting double-array: 100% |###########################################| \n",
            "reading ./matrix.def ... 3822x2693\n",
            "emitting matrix      : 100% |###########################################| \n",
            "\n",
            "done!\n",
            "echo To enable dictionary, rewrite /usr/local/etc/mecabrc as \\\"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\\\"\n",
            "To enable dictionary, rewrite /usr/local/etc/mecabrc as \"dicdir = /usr/local/lib/mecab/dic/mecab-ko-dic\"\n",
            "make[1]: Entering directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "make[1]: Nothing to be done for 'install-exec-am'.\n",
            " /bin/mkdir -p '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            " /usr/bin/install -c -m 644 model.bin matrix.bin char.bin sys.dic unk.dic left-id.def right-id.def rewrite.def pos-id.def dicrc '/usr/local/lib/mecab/dic/mecab-ko-dic'\n",
            "make[1]: Leaving directory '/tmp/mecab-ko-dic-2.1.1-20180720'\n",
            "Install mecab-python\n",
            "/tmp /tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Cloning into 'mecab-python-0.996'...\n",
            "Unpacking objects: 100% (17/17), done.\n",
            "/tmp/mecab-ko-dic-2.1.1-20180720\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Processing /tmp/mecab-python-0.996\n",
            "\u001b[33m  DEPRECATION: A future pip version will change local packages to be built in-place without first copying to a temporary directory. We recommend you use --use-feature=in-tree-build to test your packages with this new behavior before it becomes the default.\n",
            "   pip 21.3 will remove support for this functionality. You can find discussion regarding this at https://github.com/pypa/pip/issues/7555.\u001b[0m\n",
            "Building wheels for collected packages: mecab-python\n",
            "  Building wheel for mecab-python (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for mecab-python: filename=mecab_python-0.996_ko_0.9.2-cp37-cp37m-linux_x86_64.whl size=141795 sha256=3fafce759270058845ea85a8c361f022a1532e0e20e8733abc38f134392dbcfa\n",
            "  Stored in directory: /root/.cache/pip/wheels/40/7b/9f/2922869bef86c3354ae7034f7a3647c573ee1997c2dad0290a\n",
            "\u001b[33m  WARNING: Built wheel for mecab-python is invalid: Metadata 1.2 mandates PEP 440 version, but '0.996-ko-0.9.2' is not\u001b[0m\n",
            "Failed to build mecab-python\n",
            "Installing collected packages: mecab-python\n",
            "    Running setup.py install for mecab-python ... \u001b[?25l\u001b[?25hdone\n",
            "\u001b[33m  DEPRECATION: mecab-python was installed using the legacy 'setup.py install' method, because a wheel could not be built for it. A possible replacement is to fix the wheel build issue reported above. You can find discussion regarding this at https://github.com/pypa/pip/issues/8368.\u001b[0m\n",
            "Successfully installed mecab-python-0.996-ko-0.9.2\n",
            "Done.\n"
          ]
        }
      ],
      "source": [
        "!bash <(curl -s https://raw.githubusercontent.com/konlpy/konlpy/master/scripts/mecab.sh)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AK_Ccza82sYI"
      },
      "source": [
        "### code"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "sWiuEHx7yFVi"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import numpy as np\n",
        "from torch.utils.data import Dataset\n",
        "from konlpy.tag import Mecab\n",
        "from collections import Counter\n",
        "from itertools import chain\n",
        "from functools import partial\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "\n",
        "#from preprocessing import basic_preprocess, preprocess\n",
        "#def tokenize(tokenizer):\n",
        "\n",
        "class Vocab():\n",
        "    PAD_TOKEN = '<PAD>'\n",
        "    PAD_TOKEN_ID = 0\n",
        "    UNK_TOKEN = '<UNK>'\n",
        "    UNK_TOKEN_ID = 1\n",
        "    SOS_TOKEN = '<SOS>'\n",
        "    SOS_TOKEN_ID = 2\n",
        "    EOS_TOKEN = '<EOS>'\n",
        "    EOS_TOKEN_ID = 3\n",
        "\n",
        "    def __init__(self, tokenizer=Mecab, do_preprocess=True) -> None:\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "        data_path = \"./nsmc/ratings_train.txt\" \n",
        "        train_f = open(data_path, 'r', encoding=\"utf-8\")\n",
        "        lines = train_f.readlines()\n",
        "        \n",
        "        self.train_corpus, self.train_labels = [], []\n",
        "        for i in tqdm(range(len(lines)), desc=\"get_train_data\"):\n",
        "            line = lines[i]\n",
        "            if i==0:\n",
        "                continue\n",
        "            _, sentence, label = line.split(sep='\\t')\n",
        "            \n",
        "            # preprocessing\n",
        "            label = label[0]\n",
        "            sentence = self._preprocess(sentence, do_preprocess)\n",
        "            if sentence:\n",
        "                self.train_corpus.append(sentence)\n",
        "                self.train_labels.append(int(label))\n",
        "\n",
        "\n",
        "        self.test_corpus, self.test_labels = [], []\n",
        "        test_data_path = \"./nsmc/ratings_test.txt\" \n",
        "        test_f = open(test_data_path, 'r', encoding=\"utf-8\")\n",
        "        lines = test_f.readlines()\n",
        "        for i in tqdm(range(len(lines)), desc=\"get_test_data\"):\n",
        "            line = lines[i]\n",
        "            if i==0:\n",
        "                continue\n",
        "            _, sentence, label = line.split(sep='\\t')\n",
        "            # preprocessing\n",
        "            label = label[0]\n",
        "            sentence = self._preprocess(sentence, do_preprocess)\n",
        "            if sentence:\n",
        "                self.test_corpus.append(sentence)\n",
        "                self.test_labels.append(int(label))\n",
        "        \n",
        "        # test corpus도 포함해서 Vocab을 구성하는 게 맞겠죠?\n",
        "        self.train_corpus = list(map(self._tokenize_sent,self.train_corpus))\n",
        "        self.test_corpus = list(map(self._tokenize_sent,self.test_corpus))\n",
        "\n",
        "        self.id2token, self.token2id = self._build_vocab(self.train_corpus + self.test_corpus, min_freq=2)\n",
        "        self.vocab_len = len(self.token2id)\n",
        "        \n",
        "        # save\n",
        "        self.obj_to_save = [self.train_corpus, self.train_labels, self.test_corpus, self.test_labels, self.token2id, self.id2token]\n",
        "        with open('./vocab.pkl', 'wb') as f:\n",
        "            for obj in self.obj_to_save:\n",
        "                pickle.dump(obj, f, pickle.HIGHEST_PROTOCOL)\n",
        "    \n",
        "    def _preprocess(self, text, do_preprocess):\n",
        "        if do_preprocess:\n",
        "            new_text = preprocess(text)\n",
        "        else:\n",
        "            new_text = basic_preprocess(text)\n",
        "        return new_text\n",
        "\n",
        "    def _tokenize_sent(self, sentence):\n",
        "        tokens = self.tokenizer.morphs(sentence)\n",
        "        return tokens\n",
        "\n",
        "    def _build_vocab(self, tokens, min_freq=1):\n",
        "        SPECIAL_TOKENS= [self.PAD_TOKEN, self.UNK_TOKEN, self.SOS_TOKEN, self.EOS_TOKEN]\n",
        "        id2token = SPECIAL_TOKENS + [word for word, count in Counter(chain(*tokens)).items() if count >= min_freq]\n",
        "        token2id = {word: idx for idx, word in enumerate(id2token)}\n",
        "\n",
        "        assert id2token[self.UNK_TOKEN_ID] == self.UNK_TOKEN and token2id[self.UNK_TOKEN] == self.UNK_TOKEN_ID, \\\n",
        "            \"[UNK] 토큰을 적절히 삽입하세요\"\n",
        "        assert len(id2token) == len(token2id), \\\n",
        "            \"id2word과 word2id의 크기는 같아야 합니다\"\n",
        "        return id2token, token2id\n",
        "\n",
        "class NSMCDataset(Dataset):\n",
        "    def __init__(self, corpus, labels, token2id, id2token, tokenizer=Mecab()):\n",
        "        super(NSMCDataset, self).__init__()\n",
        "        print(len(token2id))\n",
        "        self.corpus = corpus\n",
        "        self.labels = labels\n",
        "        self.token2id = token2id\n",
        "        self.id2token = id2token\n",
        "        self.tokenizer = tokenizer\n",
        "        \n",
        "\n",
        "        # test corpus도 포함해서 Vocab을 구성하는 게 맞겠죠?\n",
        "        self.vocab_len = len(self.token2id)\n",
        "        self._encoding_corpus()\n",
        "        self.corpus = self.input_ids\n",
        "        #self.corpus = list(map(self._one_hot_encoding, self.input_ids))\n",
        "\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        return self.corpus[index], self.labels[index]\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.corpus)\n",
        "\n",
        "    def _encoding_corpus(self):\n",
        "        self.input_ids = list(map(partial(self._encode_sent, token2id=self.token2id), self.corpus))\n",
        "\n",
        "    def _encode_sent(self, sentence, token2id):\n",
        "        UNK_TOKEN_ID = 1\n",
        "        token_ids = torch.tensor([token2id.get(token, UNK_TOKEN_ID) for token in sentence])\n",
        "        return token_ids\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PrL40ihN2YCx"
      },
      "source": [
        "## 3. Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "lpWbKCL_yLcG"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.nn.utils.rnn import pack_padded_sequence, pad_packed_sequence\n",
        "\n",
        "class RNNClassification(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        vocab_size, \n",
        "        emb_size, \n",
        "        hidden_size=128, \n",
        "        num_layers=4):\n",
        "\n",
        "        super(RNNClassification, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
        "        self.rnn = nn.RNN(\n",
        "            input_size=emb_size, \n",
        "            hidden_size=hidden_size, \n",
        "            num_layers=num_layers, \n",
        "            batch_first=True, \n",
        "            bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        #print(x)\n",
        "        outs = self.emb(x)\n",
        "        print(\"emb:\", outs.size())\n",
        "        outs_packed = pack_padded_sequence(outs, lens, batch_first=True, enforce_sorted=False)\n",
        "        y, hidden = self.rnn(outs_packed)\n",
        "        y, lens_unpacked = pad_packed_sequence(y, batch_first=True)\n",
        "        print(\"rnn:\", y.size())\n",
        "        #y_last = y[:,-1]\n",
        "        y = torch.stack([y[i,l-1, :] for i,l in zip(range(len(y)),lens)], dim=0)\n",
        "        y = self.sigmoid(self.fc(y))\n",
        "        return y\n",
        "\n",
        "class LSTMClassification(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        vocab_size, \n",
        "        emb_size, \n",
        "        hidden_size=128, \n",
        "        num_layers=4):\n",
        "\n",
        "        super(RNNClassification, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
        "        self.lstm = nn.LSTM(\n",
        "            input_size=emb_size, \n",
        "            hidden_size=hidden_size, \n",
        "            num_layers=num_layers, \n",
        "            batch_first=True, \n",
        "            bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        #print(x)\n",
        "        outs = self.emb(x)\n",
        "        print(\"emb:\", outs.size())\n",
        "        outs_packed = pack_padded_sequence(outs, lens, batch_first=True, enforce_sorted=False)\n",
        "        y, (hidden, cell) = self.lstm(outs_packed)\n",
        "        y, lens_unpacked = pad_packed_sequence(y, batch_first=True)\n",
        "        print(\"rnn:\", y.size())\n",
        "        #y_last = y[:,-1]\n",
        "        y = torch.stack([y[i,l-1, :] for i,l in zip(range(len(y)),lens)], dim=0)\n",
        "        y = self.sigmoid(self.fc(y))\n",
        "        return y\n",
        "\n",
        "\n",
        "class GRUClassification(nn.Module):\n",
        "    def __init__(\n",
        "        self, \n",
        "        vocab_size, \n",
        "        emb_size, \n",
        "        hidden_size=128, \n",
        "        num_layers=4):\n",
        "\n",
        "        super(RNNClassification, self).__init__()\n",
        "        self.emb = nn.Embedding(vocab_size, emb_size)\n",
        "        self.gru = nn.GRU(\n",
        "            input_size=emb_size, \n",
        "            hidden_size=hidden_size, \n",
        "            num_layers=num_layers, \n",
        "            batch_first=True, \n",
        "            bidirectional=True)\n",
        "        self.fc = nn.Linear(hidden_size * 2, 1)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "        self._initialize_weights()\n",
        "    \n",
        "    def _initialize_weights(self):\n",
        "        nn.init.xavier_uniform_(self.fc.weight)\n",
        "\n",
        "\n",
        "    def forward(self, x, lens):\n",
        "        #print(x)\n",
        "        outs = self.emb(x)\n",
        "        print(\"emb:\", outs.size())\n",
        "        outs_packed = pack_padded_sequence(outs, lens, batch_first=True, enforce_sorted=False)\n",
        "        y, hidden = self.gru(outs_packed)\n",
        "        y, lens_unpacked = pad_packed_sequence(y, batch_first=True)\n",
        "        print(\"rnn:\", y.size())\n",
        "        #y_last = y[:,-1]\n",
        "        y = torch.stack([y[i,l-1, :] for i,l in zip(range(len(y)),lens)], dim=0)\n",
        "        y = self.sigmoid(self.fc(y))\n",
        "        return y\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TNscK65m2kNL"
      },
      "source": [
        "## 4. Main"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bYr8qzq_0pmT",
        "outputId": "eb1a8897-db61-4fff-b2f2-e44ee1920f55"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Set Model, Loss, Optimizer\n",
            "vocab_size :  34377\n",
            "Training...\n",
            "EPOCH:  0\n",
            "-------Train------\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 0/147 :  train_loss = 0.7064\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 1/147 :  train_loss = 1.0565\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 2/147 :  train_loss = 1.3282\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 3/147 :  train_loss = 0.7134\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 4/147 :  train_loss = 1.0075\n",
            "\n",
            "emb: torch.Size([1024, 108, 1000])\n",
            "rnn: torch.Size([1024, 108, 512])\n",
            "Epoch 1/200, iter 5/147 :  train_loss = 0.7056\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 6/147 :  train_loss = 0.7168\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 7/147 :  train_loss = 0.7697\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 8/147 :  train_loss = 0.6488\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 1/200, iter 9/147 :  train_loss = 0.6918\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 10/147 :  train_loss = 0.6941\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 11/147 :  train_loss = 0.5995\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 12/147 :  train_loss = 0.6499\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 13/147 :  train_loss = 0.6332\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 14/147 :  train_loss = 0.5845\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 15/147 :  train_loss = 0.6026\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 16/147 :  train_loss = 0.6202\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 17/147 :  train_loss = 0.5951\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 18/147 :  train_loss = 0.5313\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 19/147 :  train_loss = 0.5556\n",
            "\n",
            "emb: torch.Size([1024, 96, 1000])\n",
            "rnn: torch.Size([1024, 96, 512])\n",
            "Epoch 1/200, iter 20/147 :  train_loss = 0.5328\n",
            "\n",
            "emb: torch.Size([1024, 115, 1000])\n",
            "rnn: torch.Size([1024, 115, 512])\n",
            "Epoch 1/200, iter 21/147 :  train_loss = 0.5690\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 22/147 :  train_loss = 0.5419\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 23/147 :  train_loss = 0.5076\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 24/147 :  train_loss = 0.5372\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 25/147 :  train_loss = 0.4930\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 26/147 :  train_loss = 0.4954\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 27/147 :  train_loss = 0.4991\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 28/147 :  train_loss = 0.4814\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 29/147 :  train_loss = 0.4619\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 30/147 :  train_loss = 0.4841\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 31/147 :  train_loss = 0.4877\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 32/147 :  train_loss = 0.5030\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 33/147 :  train_loss = 0.4896\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 34/147 :  train_loss = 0.4785\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 35/147 :  train_loss = 0.5151\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 36/147 :  train_loss = 0.4604\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 37/147 :  train_loss = 0.4746\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 38/147 :  train_loss = 0.4635\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 39/147 :  train_loss = 0.4733\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 40/147 :  train_loss = 0.4782\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 41/147 :  train_loss = 0.4834\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 1/200, iter 42/147 :  train_loss = 0.4486\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 43/147 :  train_loss = 0.4547\n",
            "\n",
            "emb: torch.Size([1024, 94, 1000])\n",
            "rnn: torch.Size([1024, 94, 512])\n",
            "Epoch 1/200, iter 44/147 :  train_loss = 0.4480\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 45/147 :  train_loss = 0.4515\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 46/147 :  train_loss = 0.4990\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 1/200, iter 47/147 :  train_loss = 0.4511\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 1/200, iter 48/147 :  train_loss = 0.4417\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 49/147 :  train_loss = 0.4915\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 50/147 :  train_loss = 0.4321\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 51/147 :  train_loss = 0.4462\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 52/147 :  train_loss = 0.4871\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 1/200, iter 53/147 :  train_loss = 0.4576\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 54/147 :  train_loss = 0.4526\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 55/147 :  train_loss = 0.4570\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 56/147 :  train_loss = 0.4567\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 57/147 :  train_loss = 0.4559\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 58/147 :  train_loss = 0.4840\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 59/147 :  train_loss = 0.4449\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 60/147 :  train_loss = 0.4093\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 61/147 :  train_loss = 0.4613\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 1/200, iter 62/147 :  train_loss = 0.4596\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 63/147 :  train_loss = 0.4412\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 64/147 :  train_loss = 0.4347\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 1/200, iter 65/147 :  train_loss = 0.4310\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 66/147 :  train_loss = 0.4244\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 67/147 :  train_loss = 0.5109\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 68/147 :  train_loss = 0.4456\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 69/147 :  train_loss = 0.4433\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 1/200, iter 70/147 :  train_loss = 0.4576\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 1/200, iter 71/147 :  train_loss = 0.4053\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 72/147 :  train_loss = 0.4290\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 73/147 :  train_loss = 0.4038\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 74/147 :  train_loss = 0.4680\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 75/147 :  train_loss = 0.4269\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 76/147 :  train_loss = 0.4177\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 77/147 :  train_loss = 0.4382\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 78/147 :  train_loss = 0.4301\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 79/147 :  train_loss = 0.4294\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 80/147 :  train_loss = 0.4298\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 81/147 :  train_loss = 0.4097\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 1/200, iter 82/147 :  train_loss = 0.4350\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 83/147 :  train_loss = 0.4119\n",
            "\n",
            "emb: torch.Size([1024, 98, 1000])\n",
            "rnn: torch.Size([1024, 98, 512])\n",
            "Epoch 1/200, iter 84/147 :  train_loss = 0.4123\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 85/147 :  train_loss = 0.4328\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 86/147 :  train_loss = 0.3894\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 87/147 :  train_loss = 0.4334\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 88/147 :  train_loss = 0.3991\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 89/147 :  train_loss = 0.4033\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 90/147 :  train_loss = 0.4155\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 1/200, iter 91/147 :  train_loss = 0.3866\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 92/147 :  train_loss = 0.4277\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 93/147 :  train_loss = 0.3870\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 1/200, iter 94/147 :  train_loss = 0.4539\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 1/200, iter 95/147 :  train_loss = 0.4198\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 96/147 :  train_loss = 0.3855\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 97/147 :  train_loss = 0.4257\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 98/147 :  train_loss = 0.4247\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 1/200, iter 99/147 :  train_loss = 0.3834\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 100/147 :  train_loss = 0.4074\n",
            "\n",
            "emb: torch.Size([1024, 116, 1000])\n",
            "rnn: torch.Size([1024, 116, 512])\n",
            "Epoch 1/200, iter 101/147 :  train_loss = 0.3985\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 102/147 :  train_loss = 0.3915\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 103/147 :  train_loss = 0.3883\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 104/147 :  train_loss = 0.4083\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 1/200, iter 105/147 :  train_loss = 0.3994\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 106/147 :  train_loss = 0.3937\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 107/147 :  train_loss = 0.3958\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 108/147 :  train_loss = 0.3755\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 109/147 :  train_loss = 0.4062\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 110/147 :  train_loss = 0.3927\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 1/200, iter 111/147 :  train_loss = 0.4098\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 112/147 :  train_loss = 0.3677\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 113/147 :  train_loss = 0.4193\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 1/200, iter 114/147 :  train_loss = 0.3762\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 115/147 :  train_loss = 0.4005\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 116/147 :  train_loss = 0.3843\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 117/147 :  train_loss = 0.3869\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 118/147 :  train_loss = 0.3882\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 1/200, iter 119/147 :  train_loss = 0.3656\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 120/147 :  train_loss = 0.4199\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 121/147 :  train_loss = 0.3872\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 122/147 :  train_loss = 0.3871\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 123/147 :  train_loss = 0.4421\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 124/147 :  train_loss = 0.3956\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 125/147 :  train_loss = 0.3780\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 126/147 :  train_loss = 0.3922\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 127/147 :  train_loss = 0.4366\n",
            "\n",
            "emb: torch.Size([1024, 94, 1000])\n",
            "rnn: torch.Size([1024, 94, 512])\n",
            "Epoch 1/200, iter 128/147 :  train_loss = 0.3845\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 129/147 :  train_loss = 0.4422\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 130/147 :  train_loss = 0.4174\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 131/147 :  train_loss = 0.4172\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 132/147 :  train_loss = 0.3657\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 133/147 :  train_loss = 0.4074\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 134/147 :  train_loss = 0.3951\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 135/147 :  train_loss = 0.4207\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 136/147 :  train_loss = 0.4038\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 137/147 :  train_loss = 0.4082\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 138/147 :  train_loss = 0.3834\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 139/147 :  train_loss = 0.3800\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 140/147 :  train_loss = 0.4344\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 141/147 :  train_loss = 0.4316\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 142/147 :  train_loss = 0.4029\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 143/147 :  train_loss = 0.4011\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 144/147 :  train_loss = 0.3824\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 145/147 :  train_loss = 0.4269\n",
            "\n",
            "emb: torch.Size([491, 82, 1000])\n",
            "rnn: torch.Size([491, 82, 512])\n",
            "Epoch 1/200, iter 146/147 :  train_loss = 0.3934\n",
            "\n",
            "Epoch 1/200 :  train_avg_loss = 0.4722\n",
            "\n",
            "-------Eval------\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 0/49 : eval_loss = 0.4131\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 1/49 : eval_loss = 0.3811\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 2/49 : eval_loss = 0.4143\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 3/49 : eval_loss = 0.3870\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 4/49 : eval_loss = 0.3859\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 1/200, iter 5/49 : eval_loss = 0.4303\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 6/49 : eval_loss = 0.4119\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 7/49 : eval_loss = 0.4217\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 8/49 : eval_loss = 0.4257\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 9/49 : eval_loss = 0.4043\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 10/49 : eval_loss = 0.3760\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 11/49 : eval_loss = 0.3934\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 12/49 : eval_loss = 0.3950\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 13/49 : eval_loss = 0.3841\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 1/200, iter 14/49 : eval_loss = 0.4117\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 15/49 : eval_loss = 0.4201\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 16/49 : eval_loss = 0.4104\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 1/200, iter 17/49 : eval_loss = 0.4030\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 18/49 : eval_loss = 0.3889\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 19/49 : eval_loss = 0.3835\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 20/49 : eval_loss = 0.4121\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 1/200, iter 21/49 : eval_loss = 0.4074\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 22/49 : eval_loss = 0.3779\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 23/49 : eval_loss = 0.3861\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 24/49 : eval_loss = 0.4228\n",
            "\n",
            "emb: torch.Size([1024, 105, 1000])\n",
            "rnn: torch.Size([1024, 105, 512])\n",
            "Epoch 1/200, iter 25/49 : eval_loss = 0.4039\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 1/200, iter 26/49 : eval_loss = 0.4203\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 1/200, iter 27/49 : eval_loss = 0.3872\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 28/49 : eval_loss = 0.4173\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 29/49 : eval_loss = 0.3822\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 1/200, iter 30/49 : eval_loss = 0.4117\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 31/49 : eval_loss = 0.4185\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 1/200, iter 32/49 : eval_loss = 0.4477\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 1/200, iter 33/49 : eval_loss = 0.3907\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 1/200, iter 34/49 : eval_loss = 0.4131\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 35/49 : eval_loss = 0.4107\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 36/49 : eval_loss = 0.4108\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 1/200, iter 37/49 : eval_loss = 0.4130\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 38/49 : eval_loss = 0.4258\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 1/200, iter 39/49 : eval_loss = 0.4159\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 1/200, iter 40/49 : eval_loss = 0.4031\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 41/49 : eval_loss = 0.3623\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 1/200, iter 42/49 : eval_loss = 0.3965\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 1/200, iter 43/49 : eval_loss = 0.4000\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 1/200, iter 44/49 : eval_loss = 0.3958\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 1/200, iter 45/49 : eval_loss = 0.3802\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 1/200, iter 46/49 : eval_loss = 0.4075\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 1/200, iter 47/49 : eval_loss = 0.4295\n",
            "\n",
            "emb: torch.Size([845, 93, 1000])\n",
            "rnn: torch.Size([845, 93, 512])\n",
            "Epoch 1/200, iter 48/49 : eval_loss = 0.3884\n",
            "\n",
            "EPOCH:  1\n",
            "-------Train------\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 0/147 :  train_loss = 0.3415\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 1/147 :  train_loss = 0.3755\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 2/147 :  train_loss = 0.3149\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 3/147 :  train_loss = 0.3680\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 2/200, iter 4/147 :  train_loss = 0.3324\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 5/147 :  train_loss = 0.3475\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 6/147 :  train_loss = 0.3522\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 7/147 :  train_loss = 0.3947\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 8/147 :  train_loss = 0.3658\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 2/200, iter 9/147 :  train_loss = 0.3312\n",
            "\n",
            "emb: torch.Size([1024, 115, 1000])\n",
            "rnn: torch.Size([1024, 115, 512])\n",
            "Epoch 2/200, iter 10/147 :  train_loss = 0.3611\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 11/147 :  train_loss = 0.3471\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 2/200, iter 12/147 :  train_loss = 0.3533\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 13/147 :  train_loss = 0.3405\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 14/147 :  train_loss = 0.3626\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 15/147 :  train_loss = 0.3473\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 16/147 :  train_loss = 0.2952\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 17/147 :  train_loss = 0.3517\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 18/147 :  train_loss = 0.3836\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 19/147 :  train_loss = 0.3462\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 20/147 :  train_loss = 0.3538\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 21/147 :  train_loss = 0.3509\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 2/200, iter 22/147 :  train_loss = 0.3466\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 23/147 :  train_loss = 0.3387\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 24/147 :  train_loss = 0.3421\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 2/200, iter 25/147 :  train_loss = 0.3481\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 26/147 :  train_loss = 0.3081\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 27/147 :  train_loss = 0.3528\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 28/147 :  train_loss = 0.3386\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 29/147 :  train_loss = 0.3517\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 30/147 :  train_loss = 0.3500\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 31/147 :  train_loss = 0.3459\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 32/147 :  train_loss = 0.3219\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 33/147 :  train_loss = 0.3577\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 34/147 :  train_loss = 0.3337\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 35/147 :  train_loss = 0.3343\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 36/147 :  train_loss = 0.3438\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 37/147 :  train_loss = 0.3282\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 38/147 :  train_loss = 0.3237\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 2/200, iter 39/147 :  train_loss = 0.3071\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 40/147 :  train_loss = 0.3636\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 41/147 :  train_loss = 0.3537\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 42/147 :  train_loss = 0.3533\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 43/147 :  train_loss = 0.3603\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 44/147 :  train_loss = 0.3717\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 45/147 :  train_loss = 0.3716\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 46/147 :  train_loss = 0.3488\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 2/200, iter 47/147 :  train_loss = 0.3294\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 48/147 :  train_loss = 0.3241\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 49/147 :  train_loss = 0.3100\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 50/147 :  train_loss = 0.3112\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 51/147 :  train_loss = 0.3649\n",
            "\n",
            "emb: torch.Size([1024, 94, 1000])\n",
            "rnn: torch.Size([1024, 94, 512])\n",
            "Epoch 2/200, iter 52/147 :  train_loss = 0.3523\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 53/147 :  train_loss = 0.3273\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 54/147 :  train_loss = 0.3374\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 55/147 :  train_loss = 0.3372\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 2/200, iter 56/147 :  train_loss = 0.3318\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 57/147 :  train_loss = 0.3453\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 58/147 :  train_loss = 0.3251\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 2/200, iter 59/147 :  train_loss = 0.3093\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 60/147 :  train_loss = 0.3602\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 61/147 :  train_loss = 0.3153\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 62/147 :  train_loss = 0.3035\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 2/200, iter 63/147 :  train_loss = 0.3132\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 2/200, iter 64/147 :  train_loss = 0.3648\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 65/147 :  train_loss = 0.3286\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 2/200, iter 66/147 :  train_loss = 0.3247\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 2/200, iter 67/147 :  train_loss = 0.3504\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 2/200, iter 68/147 :  train_loss = 0.3312\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 69/147 :  train_loss = 0.3401\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 70/147 :  train_loss = 0.3166\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 71/147 :  train_loss = 0.3366\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 72/147 :  train_loss = 0.3403\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 73/147 :  train_loss = 0.3260\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 74/147 :  train_loss = 0.3438\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 75/147 :  train_loss = 0.3432\n",
            "\n",
            "emb: torch.Size([1024, 75, 1000])\n",
            "rnn: torch.Size([1024, 75, 512])\n",
            "Epoch 2/200, iter 76/147 :  train_loss = 0.3439\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 2/200, iter 77/147 :  train_loss = 0.3009\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 78/147 :  train_loss = 0.3321\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 2/200, iter 79/147 :  train_loss = 0.3285\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 80/147 :  train_loss = 0.3392\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 81/147 :  train_loss = 0.3342\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 2/200, iter 82/147 :  train_loss = 0.3133\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 83/147 :  train_loss = 0.2870\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 84/147 :  train_loss = 0.3345\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 2/200, iter 85/147 :  train_loss = 0.3342\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 2/200, iter 86/147 :  train_loss = 0.3628\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 87/147 :  train_loss = 0.3682\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 2/200, iter 88/147 :  train_loss = 0.3359\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 89/147 :  train_loss = 0.3217\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 90/147 :  train_loss = 0.3405\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 91/147 :  train_loss = 0.3487\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 92/147 :  train_loss = 0.3397\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 2/200, iter 93/147 :  train_loss = 0.3457\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 2/200, iter 94/147 :  train_loss = 0.3321\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 2/200, iter 95/147 :  train_loss = 0.3671\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 96/147 :  train_loss = 0.3225\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 97/147 :  train_loss = 0.3216\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 98/147 :  train_loss = 0.3239\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 2/200, iter 99/147 :  train_loss = 0.3933\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 100/147 :  train_loss = 0.3482\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 101/147 :  train_loss = 0.3398\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 102/147 :  train_loss = 0.3626\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 103/147 :  train_loss = 0.3830\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 2/200, iter 104/147 :  train_loss = 0.3243\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 105/147 :  train_loss = 0.3493\n",
            "\n",
            "emb: torch.Size([1024, 94, 1000])\n",
            "rnn: torch.Size([1024, 94, 512])\n",
            "Epoch 2/200, iter 106/147 :  train_loss = 0.3409\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 107/147 :  train_loss = 0.3386\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 2/200, iter 108/147 :  train_loss = 0.3005\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 109/147 :  train_loss = 0.3099\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 110/147 :  train_loss = 0.3101\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 111/147 :  train_loss = 0.3481\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 2/200, iter 112/147 :  train_loss = 0.3312\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 113/147 :  train_loss = 0.3413\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 114/147 :  train_loss = 0.4818\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 115/147 :  train_loss = 0.4097\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 2/200, iter 116/147 :  train_loss = 0.3392\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 2/200, iter 117/147 :  train_loss = 0.4008\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 118/147 :  train_loss = 0.3831\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 119/147 :  train_loss = 0.4850\n",
            "\n",
            "emb: torch.Size([1024, 98, 1000])\n",
            "rnn: torch.Size([1024, 98, 512])\n",
            "Epoch 2/200, iter 120/147 :  train_loss = 0.4103\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 121/147 :  train_loss = 0.4357\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 122/147 :  train_loss = 0.4151\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 123/147 :  train_loss = 0.4286\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 124/147 :  train_loss = 0.4464\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 125/147 :  train_loss = 0.4275\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 126/147 :  train_loss = 0.4131\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 127/147 :  train_loss = 0.4117\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 128/147 :  train_loss = 0.4150\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 2/200, iter 129/147 :  train_loss = 0.4549\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 130/147 :  train_loss = 0.4032\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 131/147 :  train_loss = 0.4003\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 132/147 :  train_loss = 0.4056\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 133/147 :  train_loss = 0.4181\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 134/147 :  train_loss = 0.3741\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 135/147 :  train_loss = 0.3746\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 2/200, iter 136/147 :  train_loss = 0.4511\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 137/147 :  train_loss = 0.4021\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 138/147 :  train_loss = 0.4044\n",
            "\n",
            "emb: torch.Size([1024, 116, 1000])\n",
            "rnn: torch.Size([1024, 116, 512])\n",
            "Epoch 2/200, iter 139/147 :  train_loss = 0.3745\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 140/147 :  train_loss = 0.4064\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 141/147 :  train_loss = 0.3701\n",
            "\n",
            "emb: torch.Size([1024, 96, 1000])\n",
            "rnn: torch.Size([1024, 96, 512])\n",
            "Epoch 2/200, iter 142/147 :  train_loss = 0.4032\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 143/147 :  train_loss = 0.4012\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 144/147 :  train_loss = 0.3856\n",
            "\n",
            "emb: torch.Size([1024, 108, 1000])\n",
            "rnn: torch.Size([1024, 108, 512])\n",
            "Epoch 2/200, iter 145/147 :  train_loss = 0.3911\n",
            "\n",
            "emb: torch.Size([491, 87, 1000])\n",
            "rnn: torch.Size([491, 87, 512])\n",
            "Epoch 2/200, iter 146/147 :  train_loss = 0.4146\n",
            "\n",
            "Epoch 2/200 :  train_avg_loss = 0.3557\n",
            "\n",
            "-------Eval------\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 0/49 : eval_loss = 0.4423\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 1/49 : eval_loss = 0.3992\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 2/49 : eval_loss = 0.4243\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 3/49 : eval_loss = 0.4225\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 4/49 : eval_loss = 0.3566\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 2/200, iter 5/49 : eval_loss = 0.4253\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 6/49 : eval_loss = 0.4377\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 7/49 : eval_loss = 0.4345\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 8/49 : eval_loss = 0.4557\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 9/49 : eval_loss = 0.4037\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 10/49 : eval_loss = 0.3937\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 11/49 : eval_loss = 0.3888\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 12/49 : eval_loss = 0.4103\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 13/49 : eval_loss = 0.4025\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 2/200, iter 14/49 : eval_loss = 0.4054\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 15/49 : eval_loss = 0.4457\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 16/49 : eval_loss = 0.3809\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 2/200, iter 17/49 : eval_loss = 0.4538\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 18/49 : eval_loss = 0.4190\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 19/49 : eval_loss = 0.3879\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 20/49 : eval_loss = 0.4228\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 2/200, iter 21/49 : eval_loss = 0.4379\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 22/49 : eval_loss = 0.3949\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 23/49 : eval_loss = 0.4180\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 24/49 : eval_loss = 0.4213\n",
            "\n",
            "emb: torch.Size([1024, 105, 1000])\n",
            "rnn: torch.Size([1024, 105, 512])\n",
            "Epoch 2/200, iter 25/49 : eval_loss = 0.4458\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 2/200, iter 26/49 : eval_loss = 0.4329\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 2/200, iter 27/49 : eval_loss = 0.4174\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 28/49 : eval_loss = 0.4504\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 29/49 : eval_loss = 0.3869\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 2/200, iter 30/49 : eval_loss = 0.4404\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 31/49 : eval_loss = 0.4019\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 2/200, iter 32/49 : eval_loss = 0.4412\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 2/200, iter 33/49 : eval_loss = 0.4142\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 2/200, iter 34/49 : eval_loss = 0.4533\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 35/49 : eval_loss = 0.4199\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 36/49 : eval_loss = 0.4356\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 2/200, iter 37/49 : eval_loss = 0.4046\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 38/49 : eval_loss = 0.4304\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 2/200, iter 39/49 : eval_loss = 0.4149\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 2/200, iter 40/49 : eval_loss = 0.4267\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 41/49 : eval_loss = 0.4130\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 2/200, iter 42/49 : eval_loss = 0.4033\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 2/200, iter 43/49 : eval_loss = 0.4060\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 2/200, iter 44/49 : eval_loss = 0.4281\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 2/200, iter 45/49 : eval_loss = 0.3683\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 2/200, iter 46/49 : eval_loss = 0.4167\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 2/200, iter 47/49 : eval_loss = 0.4901\n",
            "\n",
            "emb: torch.Size([845, 93, 1000])\n",
            "rnn: torch.Size([845, 93, 512])\n",
            "Epoch 2/200, iter 48/49 : eval_loss = 0.4245\n",
            "\n",
            "EPOCH:  2\n",
            "-------Train------\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 0/147 :  train_loss = 0.3237\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 1/147 :  train_loss = 0.4145\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 3/200, iter 2/147 :  train_loss = 0.3471\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 3/147 :  train_loss = 0.3752\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 4/147 :  train_loss = 0.3577\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 5/147 :  train_loss = 0.3708\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 6/147 :  train_loss = 0.3768\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 7/147 :  train_loss = 0.3746\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 8/147 :  train_loss = 0.3780\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 9/147 :  train_loss = 0.3683\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 10/147 :  train_loss = 0.3995\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 11/147 :  train_loss = 0.4026\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 12/147 :  train_loss = 0.3720\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 13/147 :  train_loss = 0.3604\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 3/200, iter 14/147 :  train_loss = 0.3595\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 3/200, iter 15/147 :  train_loss = 0.3609\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 16/147 :  train_loss = 0.3669\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 3/200, iter 17/147 :  train_loss = 0.3844\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 18/147 :  train_loss = 0.3624\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 19/147 :  train_loss = 0.3743\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 20/147 :  train_loss = 0.3773\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 3/200, iter 21/147 :  train_loss = 0.3593\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 22/147 :  train_loss = 0.3819\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 23/147 :  train_loss = 0.3757\n",
            "\n",
            "emb: torch.Size([1024, 115, 1000])\n",
            "rnn: torch.Size([1024, 115, 512])\n",
            "Epoch 3/200, iter 24/147 :  train_loss = 0.3296\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 25/147 :  train_loss = 0.3558\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 26/147 :  train_loss = 0.3572\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 27/147 :  train_loss = 0.3495\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 28/147 :  train_loss = 0.3508\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 29/147 :  train_loss = 0.3474\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 30/147 :  train_loss = 0.3444\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 31/147 :  train_loss = 0.3465\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 32/147 :  train_loss = 0.3233\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 33/147 :  train_loss = 0.3089\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 34/147 :  train_loss = 0.3714\n",
            "\n",
            "emb: torch.Size([1024, 108, 1000])\n",
            "rnn: torch.Size([1024, 108, 512])\n",
            "Epoch 3/200, iter 35/147 :  train_loss = 0.3314\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 36/147 :  train_loss = 0.3249\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 37/147 :  train_loss = 0.3492\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 38/147 :  train_loss = 0.3330\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 39/147 :  train_loss = 0.3069\n",
            "\n",
            "emb: torch.Size([1024, 116, 1000])\n",
            "rnn: torch.Size([1024, 116, 512])\n",
            "Epoch 3/200, iter 40/147 :  train_loss = 0.2739\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 41/147 :  train_loss = 0.3216\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 42/147 :  train_loss = 0.3361\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 43/147 :  train_loss = 0.3143\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 44/147 :  train_loss = 0.3417\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 3/200, iter 45/147 :  train_loss = 0.3360\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 46/147 :  train_loss = 0.2780\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 3/200, iter 47/147 :  train_loss = 0.3397\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 3/200, iter 48/147 :  train_loss = 0.3371\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 49/147 :  train_loss = 0.3352\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 50/147 :  train_loss = 0.3160\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 51/147 :  train_loss = 0.3198\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 52/147 :  train_loss = 0.3171\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 53/147 :  train_loss = 0.3001\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 54/147 :  train_loss = 0.2824\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 55/147 :  train_loss = 0.2877\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 56/147 :  train_loss = 0.3111\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 57/147 :  train_loss = 0.3106\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 58/147 :  train_loss = 0.2984\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 59/147 :  train_loss = 0.3042\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 60/147 :  train_loss = 0.3234\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 61/147 :  train_loss = 0.3110\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 62/147 :  train_loss = 0.2557\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 63/147 :  train_loss = 0.3491\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 64/147 :  train_loss = 0.3154\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 65/147 :  train_loss = 0.3329\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 66/147 :  train_loss = 0.2995\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 67/147 :  train_loss = 0.3428\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 68/147 :  train_loss = 0.3167\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 69/147 :  train_loss = 0.3455\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 70/147 :  train_loss = 0.3376\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 71/147 :  train_loss = 0.3211\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 72/147 :  train_loss = 0.3042\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 73/147 :  train_loss = 0.3005\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 3/200, iter 74/147 :  train_loss = 0.3266\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 75/147 :  train_loss = 0.3298\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 3/200, iter 76/147 :  train_loss = 0.3021\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 77/147 :  train_loss = 0.2957\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 78/147 :  train_loss = 0.2999\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 79/147 :  train_loss = 0.2940\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 80/147 :  train_loss = 0.3283\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 81/147 :  train_loss = 0.3202\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 82/147 :  train_loss = 0.3086\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 83/147 :  train_loss = 0.3081\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 84/147 :  train_loss = 0.2964\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 85/147 :  train_loss = 0.3046\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 86/147 :  train_loss = 0.2883\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 3/200, iter 87/147 :  train_loss = 0.3077\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 3/200, iter 88/147 :  train_loss = 0.3242\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 3/200, iter 89/147 :  train_loss = 0.3113\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 3/200, iter 90/147 :  train_loss = 0.3079\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 91/147 :  train_loss = 0.3189\n",
            "\n",
            "emb: torch.Size([1024, 94, 1000])\n",
            "rnn: torch.Size([1024, 94, 512])\n",
            "Epoch 3/200, iter 92/147 :  train_loss = 0.3185\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 3/200, iter 93/147 :  train_loss = 0.2816\n",
            "\n",
            "emb: torch.Size([1024, 98, 1000])\n",
            "rnn: torch.Size([1024, 98, 512])\n",
            "Epoch 3/200, iter 94/147 :  train_loss = 0.3224\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 95/147 :  train_loss = 0.3117\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 3/200, iter 96/147 :  train_loss = 0.3088\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 97/147 :  train_loss = 0.2455\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 98/147 :  train_loss = 0.3014\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 99/147 :  train_loss = 0.3084\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 100/147 :  train_loss = 0.3479\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 101/147 :  train_loss = 0.2916\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 102/147 :  train_loss = 0.2991\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 103/147 :  train_loss = 0.3315\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 104/147 :  train_loss = 0.3031\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 105/147 :  train_loss = 0.3029\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 106/147 :  train_loss = 0.3229\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 107/147 :  train_loss = 0.3139\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 108/147 :  train_loss = 0.3010\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 109/147 :  train_loss = 0.3300\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 110/147 :  train_loss = 0.3450\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 111/147 :  train_loss = 0.3241\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 112/147 :  train_loss = 0.2898\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 113/147 :  train_loss = 0.2875\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 3/200, iter 114/147 :  train_loss = 0.3146\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 115/147 :  train_loss = 0.3335\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 3/200, iter 116/147 :  train_loss = 0.3213\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 117/147 :  train_loss = 0.3087\n",
            "\n",
            "emb: torch.Size([1024, 77, 1000])\n",
            "rnn: torch.Size([1024, 77, 512])\n",
            "Epoch 3/200, iter 118/147 :  train_loss = 0.2962\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 119/147 :  train_loss = 0.3062\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 3/200, iter 120/147 :  train_loss = 0.3121\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 3/200, iter 121/147 :  train_loss = 0.2955\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 122/147 :  train_loss = 0.2850\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 123/147 :  train_loss = 0.3190\n",
            "\n",
            "emb: torch.Size([1024, 96, 1000])\n",
            "rnn: torch.Size([1024, 96, 512])\n",
            "Epoch 3/200, iter 124/147 :  train_loss = 0.2952\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 125/147 :  train_loss = 0.3197\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 126/147 :  train_loss = 0.3083\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 127/147 :  train_loss = 0.3392\n",
            "\n",
            "emb: torch.Size([1024, 76, 1000])\n",
            "rnn: torch.Size([1024, 76, 512])\n",
            "Epoch 3/200, iter 128/147 :  train_loss = 0.3273\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 129/147 :  train_loss = 0.3279\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 130/147 :  train_loss = 0.3210\n",
            "\n",
            "emb: torch.Size([1024, 94, 1000])\n",
            "rnn: torch.Size([1024, 94, 512])\n",
            "Epoch 3/200, iter 131/147 :  train_loss = 0.3000\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 132/147 :  train_loss = 0.3118\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 3/200, iter 133/147 :  train_loss = 0.3503\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 134/147 :  train_loss = 0.3295\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 135/147 :  train_loss = 0.3299\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 136/147 :  train_loss = 0.3221\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 137/147 :  train_loss = 0.3110\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 138/147 :  train_loss = 0.3106\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 139/147 :  train_loss = 0.2760\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 3/200, iter 140/147 :  train_loss = 0.3344\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 141/147 :  train_loss = 0.3144\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 142/147 :  train_loss = 0.3391\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 143/147 :  train_loss = 0.3430\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 144/147 :  train_loss = 0.3441\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 145/147 :  train_loss = 0.3137\n",
            "\n",
            "emb: torch.Size([491, 83, 1000])\n",
            "rnn: torch.Size([491, 83, 512])\n",
            "Epoch 3/200, iter 146/147 :  train_loss = 0.2925\n",
            "\n",
            "Epoch 3/200 :  train_avg_loss = 0.3257\n",
            "\n",
            "-------Eval------\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 0/49 : eval_loss = 0.3947\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 1/49 : eval_loss = 0.3595\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 2/49 : eval_loss = 0.3550\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 3/49 : eval_loss = 0.3432\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 4/49 : eval_loss = 0.3395\n",
            "\n",
            "emb: torch.Size([1024, 92, 1000])\n",
            "rnn: torch.Size([1024, 92, 512])\n",
            "Epoch 3/200, iter 5/49 : eval_loss = 0.4177\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 6/49 : eval_loss = 0.3710\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 3/200, iter 7/49 : eval_loss = 0.3809\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 8/49 : eval_loss = 0.4002\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 9/49 : eval_loss = 0.3757\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 10/49 : eval_loss = 0.3288\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 11/49 : eval_loss = 0.3507\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 12/49 : eval_loss = 0.3654\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 13/49 : eval_loss = 0.3711\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 3/200, iter 14/49 : eval_loss = 0.3552\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 15/49 : eval_loss = 0.3941\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 3/200, iter 16/49 : eval_loss = 0.3488\n",
            "\n",
            "emb: torch.Size([1024, 91, 1000])\n",
            "rnn: torch.Size([1024, 91, 512])\n",
            "Epoch 3/200, iter 17/49 : eval_loss = 0.3930\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 18/49 : eval_loss = 0.3698\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 19/49 : eval_loss = 0.3390\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 20/49 : eval_loss = 0.3637\n",
            "\n",
            "emb: torch.Size([1024, 93, 1000])\n",
            "rnn: torch.Size([1024, 93, 512])\n",
            "Epoch 3/200, iter 21/49 : eval_loss = 0.3758\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 22/49 : eval_loss = 0.3451\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 23/49 : eval_loss = 0.3526\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 24/49 : eval_loss = 0.3815\n",
            "\n",
            "emb: torch.Size([1024, 105, 1000])\n",
            "rnn: torch.Size([1024, 105, 512])\n",
            "Epoch 3/200, iter 25/49 : eval_loss = 0.3740\n",
            "\n",
            "emb: torch.Size([1024, 78, 1000])\n",
            "rnn: torch.Size([1024, 78, 512])\n",
            "Epoch 3/200, iter 26/49 : eval_loss = 0.3958\n",
            "\n",
            "emb: torch.Size([1024, 83, 1000])\n",
            "rnn: torch.Size([1024, 83, 512])\n",
            "Epoch 3/200, iter 27/49 : eval_loss = 0.3555\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 28/49 : eval_loss = 0.3828\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 29/49 : eval_loss = 0.3382\n",
            "\n",
            "emb: torch.Size([1024, 85, 1000])\n",
            "rnn: torch.Size([1024, 85, 512])\n",
            "Epoch 3/200, iter 30/49 : eval_loss = 0.3650\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 31/49 : eval_loss = 0.3599\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 3/200, iter 32/49 : eval_loss = 0.4175\n",
            "\n",
            "emb: torch.Size([1024, 89, 1000])\n",
            "rnn: torch.Size([1024, 89, 512])\n",
            "Epoch 3/200, iter 33/49 : eval_loss = 0.3599\n",
            "\n",
            "emb: torch.Size([1024, 88, 1000])\n",
            "rnn: torch.Size([1024, 88, 512])\n",
            "Epoch 3/200, iter 34/49 : eval_loss = 0.4067\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 35/49 : eval_loss = 0.3920\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 36/49 : eval_loss = 0.3754\n",
            "\n",
            "emb: torch.Size([1024, 86, 1000])\n",
            "rnn: torch.Size([1024, 86, 512])\n",
            "Epoch 3/200, iter 37/49 : eval_loss = 0.3819\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 38/49 : eval_loss = 0.3848\n",
            "\n",
            "emb: torch.Size([1024, 90, 1000])\n",
            "rnn: torch.Size([1024, 90, 512])\n",
            "Epoch 3/200, iter 39/49 : eval_loss = 0.3866\n",
            "\n",
            "emb: torch.Size([1024, 80, 1000])\n",
            "rnn: torch.Size([1024, 80, 512])\n",
            "Epoch 3/200, iter 40/49 : eval_loss = 0.3609\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 41/49 : eval_loss = 0.3552\n",
            "\n",
            "emb: torch.Size([1024, 82, 1000])\n",
            "rnn: torch.Size([1024, 82, 512])\n",
            "Epoch 3/200, iter 42/49 : eval_loss = 0.3730\n",
            "\n",
            "emb: torch.Size([1024, 81, 1000])\n",
            "rnn: torch.Size([1024, 81, 512])\n",
            "Epoch 3/200, iter 43/49 : eval_loss = 0.3777\n",
            "\n",
            "emb: torch.Size([1024, 79, 1000])\n",
            "rnn: torch.Size([1024, 79, 512])\n",
            "Epoch 3/200, iter 44/49 : eval_loss = 0.3577\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n",
            "Epoch 3/200, iter 45/49 : eval_loss = 0.3407\n",
            "\n",
            "emb: torch.Size([1024, 99, 1000])\n",
            "rnn: torch.Size([1024, 99, 512])\n",
            "Epoch 3/200, iter 46/49 : eval_loss = 0.3912\n",
            "\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 3/200, iter 47/49 : eval_loss = 0.4237\n",
            "\n",
            "emb: torch.Size([845, 93, 1000])\n",
            "rnn: torch.Size([845, 93, 512])\n",
            "Epoch 3/200, iter 48/49 : eval_loss = 0.3536\n",
            "\n",
            "EPOCH:  3\n",
            "-------Train------\n",
            "emb: torch.Size([1024, 84, 1000])\n",
            "rnn: torch.Size([1024, 84, 512])\n",
            "Epoch 4/200, iter 0/147 :  train_loss = 0.3017\n",
            "\n",
            "emb: torch.Size([1024, 87, 1000])\n",
            "rnn: torch.Size([1024, 87, 512])\n"
          ]
        }
      ],
      "source": [
        "from tqdm import tqdm\n",
        "import os\n",
        "import pickle\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "\n",
        "from torch.nn.utils.rnn import pad_sequence\n",
        "from torch.utils.data import DataLoader\n",
        "from konlpy.tag import Mecab\n",
        "\n",
        "#from dataset import Vocab, NSMCDataset\n",
        "#from models.rnn import RNNClassification\n",
        "#from models.lstm import LSTMClassification\n",
        "\n",
        "'''Config'''\n",
        "model_name = \"RNN\"\n",
        "batch_size = 1024\n",
        "learning_rate = 1e-3\n",
        "emb_size = 1000\n",
        "hidden_size = 256\n",
        "num_layers = 4\n",
        "num_epochs = 200\n",
        "\n",
        "'''Data'''\n",
        "print(\"Preparing Data ...\")\n",
        "# vocab\n",
        "if os.path.isfile('./vocab.pkl'):\n",
        "    vocab_objs = []\n",
        "    with open('./vocab.pkl', 'rb') as f:\n",
        "        while True:\n",
        "            try:\n",
        "                data = pickle.load(f)\n",
        "            except EOFError:\n",
        "                break\n",
        "            vocab_objs.append(data)\n",
        "    train_corpus, train_labels, test_corpus, test_labels, token2id, id2token = vocab_objs\n",
        "else:   \n",
        "    vocab = Vocab(tokenizer=Mecab(), do_preprocess=True)\n",
        "    train_corpus, train_labels, test_corpus, test_labels, token2id, id2token = vocab.train_corpus, vocab.train_labels, vocab.test_corpus, vocab.test_labels, vocab.token2id, vocab.id2token\n",
        "\n",
        "# dataset\n",
        "train_dataset = NSMCDataset(train_corpus, train_labels, token2id, id2token, tokenizer=Mecab())\n",
        "test_dataset = NSMCDataset(test_corpus, test_labels, token2id, id2token, tokenizer=Mecab())\n",
        "print(\"len train_dataset : \", len(train_dataset))\n",
        "\n",
        "\n",
        "# dataloader\n",
        "def collate_fn(batched_samples):\n",
        "    PAD_TOKEN_ID=0\n",
        "    corpus, labels = zip(*batched_samples)\n",
        "    \n",
        "    input_lengths = []\n",
        "    for sent in corpus:\n",
        "        input_lengths.append(len(sent))\n",
        "\n",
        "    src_sentences = pad_sequence([\n",
        "        torch.Tensor(sentence).to(torch.long) for sentence in corpus\n",
        "    ], batch_first=True, padding_value=PAD_TOKEN_ID)\n",
        "\n",
        "    labels = torch.tensor(labels).unsqueeze(-1)\n",
        "    return src_sentences, labels, input_lengths\n",
        "\n",
        "train_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True, collate_fn=collate_fn)\n",
        "test_loader  = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False, collate_fn=collate_fn)\n",
        "\n",
        "vocab_size = train_dataset.vocab_len\n",
        "print(\"vocab_size : \", vocab_size)\n",
        "'''Model'''\n",
        "print(\"Set Model, Loss, Optimizer\")\n",
        "#sample_sent, sample_label = next(iter(train_loader))\n",
        "#print(sample_sent,sample_label)\n",
        "vocab_size = train_dataset.vocab_len\n",
        "print(\"vocab_size : \", vocab_size)\n",
        "\n",
        "if model_name ==\"RNN\":\n",
        "    model = RNNClassification(vocab_size, emb_size, hidden_size, num_layers).to(device)\n",
        "    # model = RNN()\n",
        "elif model_name ==\"LSTM\":\n",
        "    model = LSTMClassification(vocab_size, emb_size, hidden_size, num_layers).to(device)\n",
        "elif model_name ==\"GRU\":\n",
        "  model = GRUClassification(vocab_size, emb_size, hidden_size, num_layers).to(device)\n",
        "\n",
        "'''Loss , Optimizer'''\n",
        "criterion = torch.nn.BCELoss()\n",
        "optimizer = torch.optim.Adam(params=model.parameters(), lr=learning_rate)\n",
        "\n",
        "print(\"Training...\")\n",
        "\"\"\"Training Loop\"\"\"\n",
        "for epoch in range(num_epochs):\n",
        "    print(\"EPOCH: \", epoch+1)\n",
        "    model.train()\n",
        "    total_loss = 0\n",
        "    print(\"-------Train------\")\n",
        "    for i, (sentences, labels, lens) in enumerate(train_loader):\n",
        "        # forward\n",
        "        #print(sentences.unsqueeze(-1).size())\n",
        "        sentences, labels = sentences.to(device), labels.to(device)\n",
        "        outputs = model(sentences, lens)\n",
        "\n",
        "        # loss\n",
        "        # print(outputs, labels)\n",
        "        loss = criterion(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "\n",
        "        # backward\n",
        "        optimizer.zero_grad()\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "\n",
        "        total_loss += loss.item()\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, iter {i}/{len(train_loader)} :  train_loss = {loss.item():.4f}\")\n",
        "        print()\n",
        "\n",
        "    print(f\"Epoch {epoch+1}/{num_epochs} :  train_avg_loss = {total_loss/len(train_loader):.4f}\")\n",
        "    print()\n",
        "\n",
        "    print(\"-------Eval------\")\n",
        "    model.eval()\n",
        "    for i, (sentences, labels, lens) in enumerate(test_loader):\n",
        "        # forward\n",
        "        sentences, labels = sentences.to(device), labels.to(device)\n",
        "        outputs = model(sentences, lens)\n",
        "\n",
        "        # loss\n",
        "        loss = criterion(outputs.to(torch.float32), labels.to(torch.float32))\n",
        "\n",
        "        # print\n",
        "        print(f\"Epoch {epoch+1}/{num_epochs}, iter {i}/{len(test_loader)} : eval_loss = {loss.item():.4f}\")\n",
        "        print()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1ydrW0XXcwJ5"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "RNN.ipynb",
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
