{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# torchtext==0.9.0\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchtext import data\n",
    "from torchtext.legacy.data import TabularDataset, Field, Iterator\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import re\n",
    "import urllib.request\n",
    "from konlpy.tag import Okt\n",
    "\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download NSMC dataset\n",
    "# Reference: https://wikidocs.net/44249\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_train.txt\", filename=\"ratings_train.txt\")\n",
    "# urllib.request.urlretrieve(\"https://raw.githubusercontent.com/e9t/nsmc/master/ratings_test.txt\", filename=\"ratings_test.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Training sample: 150000\n",
      "Number of Test sample: 41769\n"
     ]
    }
   ],
   "source": [
    "train_data = pd.read_table('ratings_train.txt')\n",
    "test_data = pd.read_table('ratings_test.txt')\n",
    "\n",
    "print(f'Number of Training sample: {len(train_data)}')\n",
    "print(f'Number of Test sample: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙.. 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                아 더빙.. 진짜 짜증나네요 목소리      0\n",
       "1   3819312                  흠...포스터보고 초딩영화줄....오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                      교도소 이야기구먼 ..솔직히 재미는 없다..평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화!스파이더맨에서 늙어보이기만 했던 커스틴 ...      1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146182\n",
      "2\n",
      "Number of Training sample before delete duplicates: 150000\n",
      "Number of Training sample after delete duplicates: 146183\n"
     ]
    }
   ],
   "source": [
    "# Cleaning data\n",
    "# Delete duplicates\n",
    "print(train_data['document'].nunique())     # 3,818 duplicates\n",
    "print(train_data['label'].nunique())        # label: (0,1) binary classification\n",
    "\n",
    "print(f'Number of Training sample before delete duplicates: {len(train_data)}')\n",
    "train_data.drop_duplicates(subset=['document'], inplace=True)\n",
    "print(f'Number of Training sample after delete duplicates: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id          0\n",
      "document    1\n",
      "label       0\n",
      "dtype: int64\n",
      "==============================\n",
      "            id document  label\n",
      "25857  2172111      NaN      1\n",
      "==============================\n",
      "id          0\n",
      "document    0\n",
      "label       0\n",
      "dtype: int64\n",
      "Number of Training sample after delete missing values: 146182\n"
     ]
    }
   ],
   "source": [
    "# Remove Missing values\n",
    "print(train_data.isnull().sum())\n",
    "print('='*30)\n",
    "print(train_data.loc[train_data.document.isnull()])\n",
    "\n",
    "# Drop NaN row\n",
    "train_data = train_data.dropna(how = 'any')\n",
    "print('='*30)\n",
    "print(train_data.isnull().sum())\n",
    "print(f'Number of Training sample after delete missing values: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moonc.DESKTOP-1BCQBNG\\AppData\\Local\\Temp\\ipykernel_29616\\297063566.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\")\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>document</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>9976970</td>\n",
       "      <td>아 더빙 진짜 짜증나네요 목소리</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3819312</td>\n",
       "      <td>흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>10265843</td>\n",
       "      <td>너무재밓었다그래서보는것을추천한다</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>9045019</td>\n",
       "      <td>교도소 이야기구먼 솔직히 재미는 없다평점 조정</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6483659</td>\n",
       "      <td>사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                                           document  label\n",
       "0   9976970                                  아 더빙 진짜 짜증나네요 목소리      0\n",
       "1   3819312                         흠포스터보고 초딩영화줄오버연기조차 가볍지 않구나      1\n",
       "2  10265843                                  너무재밓었다그래서보는것을추천한다      0\n",
       "3   9045019                          교도소 이야기구먼 솔직히 재미는 없다평점 조정      0\n",
       "4   6483659  사이몬페그의 익살스런 연기가 돋보였던 영화스파이더맨에서 늙어보이기만 했던 커스틴 던...      1"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove punctuations\n",
    "train_data['document'] = train_data['document'].str.replace(\"[^ㄱ-ㅎㅏ-ㅣ가-힣 ]\", \"\")\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id            0\n",
      "document    789\n",
      "label         0\n",
      "dtype: int64\n",
      "Number of Training sample after delete empty documents: 145393\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moonc.DESKTOP-1BCQBNG\\AppData\\Local\\Temp\\ipykernel_29616\\3382272693.py:2: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  train_data['document'] = train_data['document'].str.replace('^ +', '')\n"
     ]
    }
   ],
   "source": [
    "# 기존에 한글 없는 리뷰 빈 document가 되므로 Null로 변경 후 제거\n",
    "train_data['document'] = train_data['document'].str.replace('^ +', '')\n",
    "train_data['document'].replace('', np.nan, inplace=True)\n",
    "print(train_data.isnull().sum())\n",
    "train_data = train_data.dropna(how='any')\n",
    "print(f'Number of Training sample after delete empty documents: {len(train_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Test sample after preprocessing: 40864\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\moonc.DESKTOP-1BCQBNG\\AppData\\Local\\Temp\\ipykernel_900\\1011012349.py:3: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '')\n",
      "C:\\Users\\moonc.DESKTOP-1BCQBNG\\AppData\\Local\\Temp\\ipykernel_900\\1011012349.py:4: FutureWarning: The default value of regex will change from True to False in a future version.\n",
      "  test_data['document'] = test_data['document'].str.replace('^ +', '')\n"
     ]
    }
   ],
   "source": [
    "# Same procedure for test dataset\n",
    "test_data.drop_duplicates(subset=['document'], inplace=True)    # Delete duplicates\n",
    "test_data['document'] = test_data['document'].str.replace('[^ㄱ-ㅎㅏ-ㅣ가-힣 ]', '')\n",
    "test_data['document'] = test_data['document'].str.replace('^ +', '')\n",
    "test_data['document'].replace('', np.nan, inplace=True)\n",
    "test_data = test_data.dropna(how='any') # Delete NaN values\n",
    "print(f'Number of Test sample after preprocessing: {len(test_data)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization\n",
    "okt = Okt()\n",
    "okt.morphs('아 더빙 진짜 짜증나네요 목소리', stem=True)\n",
    "\n",
    "# Stopwords\n",
    "stopwords = ['의','가','이','은','들','는','좀','잘','걍','과','도','를','으로','자','에','와','한','하다']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenization + Remove stopwords\n",
    "X_train = []\n",
    "for sentence in tqdm(train_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if word not in stopwords]\n",
    "    X_train.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 40864/40864 [04:20<00:00, 157.15it/s]\n"
     ]
    }
   ],
   "source": [
    "# Tokenization + Remove stopwords\n",
    "X_test = []\n",
    "for sentence in tqdm(test_data['document']):\n",
    "    tokenized_sentence = okt.morphs(sentence, stem=True)\n",
    "    stopwords_removed_sentence = [word for word in tokenized_sentence if not word in stopwords]\n",
    "    X_test.append(stopwords_removed_sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_joined = [' '.join(x) for x in X_train]\n",
    "X_test_joined = [' '.join(x) for x in X_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data['document'] = X_train_joined\n",
    "test_data['document'] = X_test_joined"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data.to_csv(\"train_data.csv\", index=False)\n",
    "test_data.to_csv(\"test_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Padding = 30\n",
    "# https://wikidocs.net/60314\n",
    "ID = Field(sequential=False, use_vocab=False)   # 실제 사용안함.\n",
    "TEXT = Field(sequential=True, use_vocab=True, tokenize=str.split, lower=True, batch_first=True, fix_length=30)\n",
    "LABEL = Field(sequential=False, use_vocab=False, batch_first=False, is_target=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data = TabularDataset.splits(path='.', train='ratings_train.txt', test='ratings_test.txt',\n",
    "#                                               format='tsv', fields=[('id', ID), ('text', TEXT), ('label', LABEL)], skip_header=True)\n",
    "train_data, test_data = TabularDataset.splits(path='.', train='train_data.csv', test='test_data.csv',\n",
    "                                              format='csv', fields=[('id', ID), ('text', TEXT), ('label', LABEL)], skip_header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training sample: 145393\n",
      "Num test sample: 40864\n",
      "dict_items([('id', <torchtext.legacy.data.field.Field object at 0x00000238C67F3940>), ('text', <torchtext.legacy.data.field.Field object at 0x00000238C67F39A0>), ('label', <torchtext.legacy.data.field.Field object at 0x00000238C67F38E0>)])\n"
     ]
    }
   ],
   "source": [
    "print(f'Num training sample: {len(train_data)}')\n",
    "print(f'Num test sample: {len(test_data)}')\n",
    "print(train_data.fields.items())    # ID, text, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT.build_vocab(train_data, min_freq=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Num training batches: 145393\n",
      "Num test batchsed: 40864\n"
     ]
    }
   ],
   "source": [
    "batch_size = 1\n",
    "train_loader = Iterator(dataset=train_data, batch_size=batch_size)\n",
    "test_loader = Iterator(dataset=test_data, batch_size=batch_size)\n",
    "\n",
    "print(f'Num training batches: {len(train_loader)}')\n",
    "print(f'Num test batchsed: {len(test_loader)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RNN(nn.Module):\n",
    "    def __init__(self, embedding_size, input_size, hidden_size, output_size):\n",
    "        super(RNN, self).__init__()\n",
    "        self.embedding = nn.Embedding(embedding_size, input_size, padding_idx=1)\n",
    "        self.hidden_size = hidden_size\n",
    "        self.input_size = input_size\n",
    "        self.i2h = nn.Linear(input_size+hidden_size, hidden_size)\n",
    "        self.i2o = nn.Linear(hidden_size, output_size)\n",
    "        # self.softmax = nn.LogSoftmax(dim=1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, input, hidden):\n",
    "        # input = self.embedding(input).view(1, -1)\n",
    "        # combined = torch.cat((input, hidden), dim=1)\n",
    "        # hidden = torch.tanh(self.i2h(combined))\n",
    "        # output = self.softmax(self.i2o(combined))\n",
    "\n",
    "        input = self.embedding(input).unsqueeze(1)\n",
    "        for i in range(self.input_size):\n",
    "            combined = torch.cat((input[i], hidden), dim=1)     # wx + wh + b\n",
    "            hidden = self.i2h(combined)\n",
    "            hidden = torch.tanh(hidden)\n",
    "        output = self.i2o(hidden)\n",
    "        #output = self.softmax(output)\n",
    "        output = self.sigmoid(output)\n",
    "\n",
    "        return output, hidden\n",
    "\n",
    "    def init_hidden(self):\n",
    "        return torch.zeros(1, self.hidden_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_tensor, label): \n",
    "    hidden = rnn.init_hidden()\n",
    "\n",
    "    # for i in range(input_tensor.size()[0]):\n",
    "    #     print(input_tensor[i].size(), hidden.size())\n",
    "    #     output, hidden = rnn(input_tensor[i], hidden)\n",
    "    output, hidden = rnn(input_tensor, hidden)\n",
    "    loss = criterion(output[0], label.float())\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    return output, loss.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = len(TEXT.vocab)\n",
    "rnn = RNN(vocab_size, 30, 128, 1)\n",
    "criterion = nn.BCELoss()\n",
    "learning_rate = 0.0001\n",
    "optimizer = torch.optim.SGD(rnn.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 2\n",
    "current_loss = 0\n",
    "plot_steps, print_steps = 1000, 2000\n",
    "all_losses = []\n",
    "\n",
    "for i in range(n_epochs):\n",
    "    for i, sample in enumerate(train_loader):\n",
    "        text = sample.text[0]\n",
    "        label = sample.label\n",
    "        output, loss = train(text, label)\n",
    "        current_loss += loss\n",
    "        if (i+1) % plot_steps == 0:\n",
    "            all_losses.append(current_loss / plot_steps)\n",
    "            current_loss = 0\n",
    "        if (i+1) % print_steps == 0:\n",
    "            guess = round(output.item())\n",
    "            correct = \"CORRECT\" if guess == label else f\"WRONG ({label.item()}) | {output.item()}\"\n",
    "            print(f\"{i} {n_epochs*len(train_loader)} {loss:.4f} {guess} {correct}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.13 ('pt_tutorial')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "9056d81a49322299aa21888e3051b56329f6cabafb6903cd933669cf0492c109"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
